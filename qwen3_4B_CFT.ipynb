{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be1ec40740334c4db8d8dbb030f727ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_396666e4a682472abd8fb1f766f21134",
              "IPY_MODEL_58e98088b4014d65abe66220deb963b6",
              "IPY_MODEL_a877de79395242f1b3ca2c182232c505"
            ],
            "layout": "IPY_MODEL_1e58a423fd564f89a4b0a87f28dee728"
          }
        },
        "396666e4a682472abd8fb1f766f21134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80f048aec055482ea36d395943ac22eb",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a8e6cf320c455bb71c43798c831ff9",
            "value": ""
          }
        },
        "58e98088b4014d65abe66220deb963b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe854d3158c49f5bb380ef07ab7c23d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4f5d2ba12444c2c88c2880a27be221b",
            "value": 1
          }
        },
        "a877de79395242f1b3ca2c182232c505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23e27b44a6db4a8fa7836cad9a5e0e42",
            "placeholder": "​",
            "style": "IPY_MODEL_a97c8609dc454cb4a21058b0412ff659",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.54s/it]\n"
          }
        },
        "1e58a423fd564f89a4b0a87f28dee728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f048aec055482ea36d395943ac22eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a8e6cf320c455bb71c43798c831ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffe854d3158c49f5bb380ef07ab7c23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f5d2ba12444c2c88c2880a27be221b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23e27b44a6db4a8fa7836cad9a5e0e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97c8609dc454cb4a21058b0412ff659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c919822cae0648269a2ab5f4e3ae4322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6b0f295ab2a4bab8c2ae0ca44a29cb2",
              "IPY_MODEL_1b5beb2ceb7744beb7a7aa39257853b1",
              "IPY_MODEL_da53bc0ef61749b39916f4edaf51a2af"
            ],
            "layout": "IPY_MODEL_3142ef6eb4f24b66ae11af4872930ef3"
          }
        },
        "e6b0f295ab2a4bab8c2ae0ca44a29cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94013b7f991a42699176d689e69fe2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_008a45c08399438591f8ceb74181281c",
            "value": ""
          }
        },
        "1b5beb2ceb7744beb7a7aa39257853b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398c9584c7564512b26a0c6dcc00326e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19844a1849d24760bce96891a0868e14",
            "value": 1
          }
        },
        "da53bc0ef61749b39916f4edaf51a2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c53f88dce9d4d1babd030c056a88356",
            "placeholder": "​",
            "style": "IPY_MODEL_a34b7299507f42428b3784c3c8043749",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.41s/it]\n"
          }
        },
        "3142ef6eb4f24b66ae11af4872930ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94013b7f991a42699176d689e69fe2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008a45c08399438591f8ceb74181281c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "398c9584c7564512b26a0c6dcc00326e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19844a1849d24760bce96891a0868e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c53f88dce9d4d1babd030c056a88356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34b7299507f42428b3784c3c8043749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f381d24a0cb457dab38da9401f88b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ff6c648a6ac4f9ea656643b4c5144e4",
              "IPY_MODEL_469835de9b084782aaa5cf6eada190d0",
              "IPY_MODEL_25972d7eb1f2497784efa0cb0107a903"
            ],
            "layout": "IPY_MODEL_56bc1351bf464823b929fe0352fca46b"
          }
        },
        "1ff6c648a6ac4f9ea656643b4c5144e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a35edf7b1ca438ebe87e3dcbd0ad088",
            "placeholder": "​",
            "style": "IPY_MODEL_7a1752bc0fc541418e9b128d8facddca",
            "value": "Capturing CUDA graph shapes: 100%"
          }
        },
        "469835de9b084782aaa5cf6eada190d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0984d12d219c42e5a06714e028df3c55",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5ba615a221a48ca91ee8d03cb00aa18",
            "value": 27
          }
        },
        "25972d7eb1f2497784efa0cb0107a903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a5cdaab2e3842c69ee507417db4d004",
            "placeholder": "​",
            "style": "IPY_MODEL_930c772f330d4a248a43ba38cd7bd60e",
            "value": " 27/27 [00:45&lt;00:00,  1.64s/it]"
          }
        },
        "56bc1351bf464823b929fe0352fca46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a35edf7b1ca438ebe87e3dcbd0ad088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1752bc0fc541418e9b128d8facddca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0984d12d219c42e5a06714e028df3c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ba615a221a48ca91ee8d03cb00aa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a5cdaab2e3842c69ee507417db4d004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930c772f330d4a248a43ba38cd7bd60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9340b14bd8c42149affacdbb583c33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68b8b097896241cd87573255c9c57f77",
              "IPY_MODEL_b092c1a7922045bbbbc9453b91cf0d6d",
              "IPY_MODEL_1be2d5af29e34c94a5a8bdf9c6da69cb"
            ],
            "layout": "IPY_MODEL_70fbfd5d0352474bb4a0ba039266b439"
          }
        },
        "68b8b097896241cd87573255c9c57f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9e9bb549b24ad9b12a2ef4549d388a",
            "placeholder": "​",
            "style": "IPY_MODEL_f052fbd3adb2495c9f904e9e9db11a8a",
            "value": "100%"
          }
        },
        "b092c1a7922045bbbbc9453b91cf0d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8241c2e2422842b9875982e11377a086",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b738f9f1a6e64fbb9825e9b5b1a0143c",
            "value": 1
          }
        },
        "1be2d5af29e34c94a5a8bdf9c6da69cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_089d7d2a184c490581cbe2a5141b69ad",
            "placeholder": "​",
            "style": "IPY_MODEL_8f00c63122304fd699b51fd6e63ed249",
            "value": " 1/1 [00:22&lt;00:00, 22.42s/it]"
          }
        },
        "70fbfd5d0352474bb4a0ba039266b439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9e9bb549b24ad9b12a2ef4549d388a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f052fbd3adb2495c9f904e9e9db11a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8241c2e2422842b9875982e11377a086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b738f9f1a6e64fbb9825e9b5b1a0143c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "089d7d2a184c490581cbe2a5141b69ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f00c63122304fd699b51fd6e63ed249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6389d4ab46d943d7bcd116e735fd0f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce030858ac7445ce9d8aad9857cac28f",
              "IPY_MODEL_cfb7f01961f64087823b9e70973dbf1f",
              "IPY_MODEL_d51ca97c7bc54bdeb402f9992b96d628"
            ],
            "layout": "IPY_MODEL_26d4d2439ab8475abc4ecc7ece94e541"
          }
        },
        "ce030858ac7445ce9d8aad9857cac28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d04c146cba4f6f99d0d7ce4ad29af8",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e43b8c67b9406683191ecf1f99907d",
            "value": "unsloth.Q4_K_M.gguf: "
          }
        },
        "cfb7f01961f64087823b9e70973dbf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b68a60ca05c47ffa70d4235caab720b",
            "max": 2497276032,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8d988bf379349419b66408ffc14df9e",
            "value": 2497276032
          }
        },
        "d51ca97c7bc54bdeb402f9992b96d628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6cd22cac26a4a1a880624536f1bdc9f",
            "placeholder": "​",
            "style": "IPY_MODEL_32e180a9b48644808f862836ad7c2c7f",
            "value": " 2.51G/? [00:21&lt;00:00, 396MB/s]"
          }
        },
        "26d4d2439ab8475abc4ecc7ece94e541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d04c146cba4f6f99d0d7ce4ad29af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e43b8c67b9406683191ecf1f99907d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b68a60ca05c47ffa70d4235caab720b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d988bf379349419b66408ffc14df9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6cd22cac26a4a1a880624536f1bdc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e180a9b48644808f862836ad7c2c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5cFt7noHGGVA"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "\n",
        "# First install unsloth and vllm\n",
        "!pip install unsloth vllm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Remove all PIL-related modules from memory\n",
        "modules = list(sys.modules.keys())\n",
        "for module_name in modules:\n",
        "    if \"PIL\" in module_name or \"torch\" in module_name or \"unsloth\" in module_name:\n",
        "        sys.modules.pop(module_name)"
      ],
      "metadata": {
        "id": "GDkmtvncGVJH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
        "lora_rank = 64 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen3-4B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.5, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827,
          "referenced_widgets": [
            "be1ec40740334c4db8d8dbb030f727ed",
            "396666e4a682472abd8fb1f766f21134",
            "58e98088b4014d65abe66220deb963b6",
            "a877de79395242f1b3ca2c182232c505",
            "1e58a423fd564f89a4b0a87f28dee728",
            "80f048aec055482ea36d395943ac22eb",
            "c0a8e6cf320c455bb71c43798c831ff9",
            "ffe854d3158c49f5bb380ef07ab7c23d",
            "b4f5d2ba12444c2c88c2880a27be221b",
            "23e27b44a6db4a8fa7836cad9a5e0e42",
            "a97c8609dc454cb4a21058b0412ff659",
            "c919822cae0648269a2ab5f4e3ae4322",
            "e6b0f295ab2a4bab8c2ae0ca44a29cb2",
            "1b5beb2ceb7744beb7a7aa39257853b1",
            "da53bc0ef61749b39916f4edaf51a2af",
            "3142ef6eb4f24b66ae11af4872930ef3",
            "94013b7f991a42699176d689e69fe2b1",
            "008a45c08399438591f8ceb74181281c",
            "398c9584c7564512b26a0c6dcc00326e",
            "19844a1849d24760bce96891a0868e14",
            "8c53f88dce9d4d1babd030c056a88356",
            "a34b7299507f42428b3784c3c8043749",
            "4f381d24a0cb457dab38da9401f88b81",
            "1ff6c648a6ac4f9ea656643b4c5144e4",
            "469835de9b084782aaa5cf6eada190d0",
            "25972d7eb1f2497784efa0cb0107a903",
            "56bc1351bf464823b929fe0352fca46b",
            "4a35edf7b1ca438ebe87e3dcbd0ad088",
            "7a1752bc0fc541418e9b128d8facddca",
            "0984d12d219c42e5a06714e028df3c55",
            "e5ba615a221a48ca91ee8d03cb00aa18",
            "1a5cdaab2e3842c69ee507417db4d004",
            "930c772f330d4a248a43ba38cd7bd60e"
          ]
        },
        "id": "yS2POVteHEuZ",
        "outputId": "df918713-5c25-44d9-8824-a0249d390006"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 06-04 13:35:41 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 06-04 13:35:42 [__init__.py:239] Automatically detected platform cuda.\n",
            "==((====))==  Unsloth 2025.5.9: Fast Qwen3 patching. Transformers: 4.52.3. vLLM: 0.8.5.post1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen3-4b-unsloth-bnb-4bit with actual GPU utilization = 49.53%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.44 GB. Also swap space = 0 GB.\n",
            "WARNING 06-04 13:36:03 [config.py:2972] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 06-04 13:36:19 [config.py:717] This model supports multiple tasks: {'reward', 'classify', 'score', 'embed', 'generate'}. Defaulting to 'generate'.\n",
            "WARNING 06-04 13:36:19 [arg_utils.py:1658] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.4.mlp', 'model.layers.6.self_attn', 'model.layers.34.self_attn', 'model.layers.33.self_attn', 'model.layers.4.self_attn', 'model.layers.34.mlp', 'model.layers.1.self_attn', 'model.layers.1.mlp', 'model.layers.0.mlp', 'model.layers.0.self_attn', 'model.layers.3.mlp', 'model.layers.6.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 06-04 13:36:19 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen3-4b-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-4b-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen3-4b-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"backend\":\"inductor\",\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n",
            "INFO 06-04 13:36:22 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 06-04 13:36:22 [cuda.py:289] Using XFormers backend.\n",
            "INFO 06-04 13:36:22 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
            "INFO 06-04 13:36:22 [model_runner.py:1108] Starting to load model unsloth/qwen3-4b-unsloth-bnb-4bit...\n",
            "INFO 06-04 13:36:23 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 06-04 13:36:24 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
            "INFO 06-04 13:36:25 [weight_utils.py:281] Time spent downloading weights for unsloth/qwen3-4b-unsloth-bnb-4bit: 0.529967 seconds\n",
            "INFO 06-04 13:36:25 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be1ec40740334c4db8d8dbb030f727ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c919822cae0648269a2ab5f4e3ae4322"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 06-04 13:36:28 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 06-04 13:36:29 [model_runner.py:1140] Model loading took 3.5738 GiB and 5.939078 seconds\n",
            "INFO 06-04 13:36:33 [worker.py:287] Memory profiling takes 3.63 seconds\n",
            "INFO 06-04 13:36:33 [worker.py:287] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.50) = 7.30GiB\n",
            "INFO 06-04 13:36:33 [worker.py:287] model weights take 3.57GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 2.65GiB.\n",
            "INFO 06-04 13:36:34 [executor_base.py:112] # cuda blocks: 1206, # CPU blocks: 0\n",
            "INFO 06-04 13:36:34 [executor_base.py:117] Maximum concurrency for 1024 tokens per request: 18.84x\n",
            "INFO 06-04 13:36:34 [model_runner.py:1450] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Capturing CUDA graph shapes:   0%|          | 0/27 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f381d24a0cb457dab38da9401f88b81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 06-04 13:37:19 [model_runner.py:1592] Graph capturing finished in 45 secs, took 0.63 GiB\n",
            "INFO 06-04 13:37:19 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 50.16 seconds\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.9 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZqbZoeBSAzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset samples { display-mode: \"form\" }\n",
        "disaster_samples = [\n",
        "    {\n",
        "        \"request\": \"URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567\",\n",
        "        \"reasoning\": \"This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Downtown Manila\",\n",
        "            \"disaster_type\": \"flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"15 families\",\n",
        "            \"specific_needs\": [\"rescue boats\"],\n",
        "            \"contact_info\": \"Maria 09171234567\",\n",
        "            \"time_mentioned\": \"urgent\",\n",
        "            \"additional_details\": \"families trapped on rooftops\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123.\",\n",
        "        \"reasoning\": \"This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"123 Oak Street\",\n",
        "            \"disaster_type\": \"house fire\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"2 elderly residents\",\n",
        "            \"specific_needs\": [\"evacuation assistance\"],\n",
        "            \"contact_info\": \"John 555-0123\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"elderly residents unable to evacuate alone\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP.\",\n",
        "        \"reasoning\": \"Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Kathmandu\",\n",
        "            \"disaster_type\": \"building collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"20 people trapped\",\n",
        "            \"specific_needs\": [\"heavy rescue equipment\", \"trained rescue personnel\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ASAP\",\n",
        "            \"additional_details\": \"voices heard from under debris\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Earthquake hit Cebu City. School building damaged, 50 children evacuated safely but 3 teachers missing. Contact: Principal Rosa 09123456789\",\n",
        "        \"reasoning\": \"Earthquake emergency with damaged school building. Children are safe but teachers are missing, indicating ongoing search needs. School setting makes this high priority.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Cebu City\",\n",
        "            \"disaster_type\": \"earthquake\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"3 teachers missing, 50 children evacuated\",\n",
        "            \"specific_needs\": [\"search and rescue\", \"building assessment\"],\n",
        "            \"contact_info\": \"Principal Rosa 09123456789\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"school building damaged, children evacuated safely\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Wildfire approaching Baguio residential area. 200 families need immediate evacuation. Smoke inhalation cases reported. Call Emergency Coordinator Ben 0917-555-0100\",\n",
        "        \"reasoning\": \"Wildfire threatening residential area with large number of families at risk. Medical concerns with smoke inhalation make this critical. Large scale evacuation needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Baguio residential area\",\n",
        "            \"disaster_type\": \"wildfire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"200 families\",\n",
        "            \"specific_needs\": [\"mass evacuation\", \"medical assistance\"],\n",
        "            \"contact_info\": \"Ben 0917-555-0100\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"smoke inhalation cases reported\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Landslide blocked highway in Benguet. 5 vehicles buried, unknown number of casualties. Heavy equipment needed urgently.\",\n",
        "        \"reasoning\": \"Landslide with vehicles buried and unknown casualties makes this critical. Highway blockage suggests multiple people potentially trapped. Heavy equipment needed for rescue.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Highway in Benguet\",\n",
        "            \"disaster_type\": \"landslide\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"unknown casualties in 5 vehicles\",\n",
        "            \"specific_needs\": [\"heavy equipment\", \"search and rescue\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"urgently\",\n",
        "            \"additional_details\": \"highway blocked, vehicles buried\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Typhoon Maring causing severe flooding in Marikina. Water level rising fast. 30 senior citizens need rescue from care facility. Contact: Nurse Linda 09285555678\",\n",
        "        \"reasoning\": \"Typhoon-related flooding with vulnerable population (seniors) needing rescue. Rising water levels indicate deteriorating conditions requiring immediate action.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Marikina\",\n",
        "            \"disaster_type\": \"typhoon/flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"30 senior citizens\",\n",
        "            \"specific_needs\": [\"water rescue\", \"medical support\"],\n",
        "            \"contact_info\": \"Nurse Linda 09285555678\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"care facility, water level rising fast\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Gas explosion at apartment complex in Makati. 8 units affected, 4 people injured, 2 missing. Firefighters on scene need medical backup. Contact: Fire Chief Santos 555-0200\",\n",
        "        \"reasoning\": \"Gas explosion with injuries and missing persons. Firefighters already responding but need medical support. Multiple units affected indicates significant incident.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Apartment complex in Makati\",\n",
        "            \"disaster_type\": \"gas explosion\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"4 injured, 2 missing\",\n",
        "            \"specific_needs\": [\"medical backup\", \"search and rescue\"],\n",
        "            \"contact_info\": \"Fire Chief Santos 555-0200\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"8 units affected, firefighters on scene\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Flash flood in Laguna. Bridge collapsed, 12 vehicles stranded on both sides. Pregnant woman in labor needs immediate medical evacuation. Contact: Barangay Captain Torres 09178888900\",\n",
        "        \"reasoning\": \"Flash flood with bridge collapse creating access problems. Medical emergency with pregnant woman in labor makes this critical. Multiple vehicles stranded indicates many people affected.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Laguna\",\n",
        "            \"disaster_type\": \"flash flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"pregnant woman in labor, occupants of 12 vehicles\",\n",
        "            \"specific_needs\": [\"medical evacuation\", \"bridge assessment\", \"vehicle rescue\"],\n",
        "            \"contact_info\": \"Barangay Captain Torres 09178888900\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"bridge collapsed, woman in labor\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Industrial fire at chemical plant in Bataan. Toxic smoke spreading. 500 workers evacuated but 10 unaccounted for. Hazmat team needed. Call Plant Manager Cruz 555-0300\",\n",
        "        \"reasoning\": \"Industrial chemical fire with toxic hazards affecting large workforce. Missing workers and toxic smoke make this critical with specialized hazmat needs.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Chemical plant in Bataan\",\n",
        "            \"disaster_type\": \"industrial fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"500 workers evacuated, 10 unaccounted for\",\n",
        "            \"specific_needs\": [\"hazmat team\", \"search and rescue\", \"air quality monitoring\"],\n",
        "            \"contact_info\": \"Plant Manager Cruz 555-0300\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"toxic smoke spreading\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Tornado touched down in Tarlac farmland. 3 farmhouses destroyed, family of 6 trapped in storm cellar. Cannot make contact. GPS coordinates: 15.4817°N, 120.5979°E\",\n",
        "        \"reasoning\": \"Tornado with destroyed structures and family trapped underground. Loss of contact makes this critical. GPS coordinates provided for precise location.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Tarlac farmland, GPS: 15.4817°N, 120.5979°E\",\n",
        "            \"disaster_type\": \"tornado\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"family of 6 trapped\",\n",
        "            \"specific_needs\": [\"search and rescue\", \"debris removal\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"3 farmhouses destroyed, no contact with trapped family\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Dam overflow in Rizal province. Downstream villages flooding rapidly. 1000 residents need evacuation within 2 hours. Contact: Mayor Dela Cruz 09171111222\",\n",
        "        \"reasoning\": \"Dam overflow creating imminent flood threat to large population. Time-critical evacuation needed for 1000 people within 2 hours makes this critical.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Downstream villages, Rizal province\",\n",
        "            \"disaster_type\": \"dam overflow/flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"1000 residents\",\n",
        "            \"specific_needs\": [\"mass evacuation\", \"transportation\"],\n",
        "            \"contact_info\": \"Mayor Dela Cruz 09171111222\",\n",
        "            \"time_mentioned\": \"within 2 hours\",\n",
        "            \"additional_details\": \"villages flooding rapidly\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Oil tanker crash on EDSA. Vehicle overturned, fuel spilling. Traffic backed up for miles. Driver trapped but conscious. Need specialized extraction team. Contact: Highway Patrol Officer Reyes 555-0400\",\n",
        "        \"reasoning\": \"Oil tanker accident with fuel spill creating environmental and fire hazards. Driver trapped but conscious. Traffic implications affect many people.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"EDSA\",\n",
        "            \"disaster_type\": \"vehicle accident/hazmat\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"1 driver trapped, traffic backed up for miles\",\n",
        "            \"specific_needs\": [\"specialized extraction\", \"hazmat response\", \"traffic control\"],\n",
        "            \"contact_info\": \"Officer Reyes 555-0400\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"overturned tanker, fuel spilling, driver conscious\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Sinkhole opened on busy street in Iloilo. 2 cars fell in, 5 people trapped 15 feet down. Water pipe burst adding to danger. Contact: City Engineer Morales 09184444333\",\n",
        "        \"reasoning\": \"Sudden sinkhole with vehicles and people trapped below ground. Broken water pipe adds drowning risk. Urban location with potential for more casualties.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Busy street in Iloilo\",\n",
        "            \"disaster_type\": \"sinkhole\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"5 people trapped\",\n",
        "            \"specific_needs\": [\"technical rescue\", \"water pumping\", \"area evacuation\"],\n",
        "            \"contact_info\": \"City Engineer Morales 09184444333\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"2 cars fell in, 15 feet deep, water pipe burst\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Hospital fire in Davao City. ICU patients need emergency transfer. 12 critical patients on life support. Ambulances en route but need helicopter for 3 most critical. Dr. Perez 555-0500\",\n",
        "        \"reasoning\": \"Hospital fire with critical ICU patients requiring immediate medical evacuation. Life support patients create time-critical medical emergency requiring specialized transport.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Hospital in Davao City\",\n",
        "            \"disaster_type\": \"hospital fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"12 critical patients\",\n",
        "            \"specific_needs\": [\"medical helicopter\", \"intensive care transport\", \"receiving hospital coordination\"],\n",
        "            \"contact_info\": \"Dr. Perez 555-0500\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"ICU patients on life support, 3 most critical need helicopter\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Mudslide hit mountain resort in Tagaytay. Resort building tilting dangerously. 40 guests and staff inside afraid to move. Structural engineer needed immediately. Contact: Resort Manager Kim 09177777888\",\n",
        "        \"reasoning\": \"Mudslide affecting resort with building structural integrity compromised. People trapped inside afraid to move due to tilting building. Structural assessment critical.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Mountain resort in Tagaytay\",\n",
        "            \"disaster_type\": \"mudslide\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"40 guests and staff\",\n",
        "            \"specific_needs\": [\"structural engineer\", \"technical rescue\", \"building stabilization\"],\n",
        "            \"contact_info\": \"Resort Manager Kim 09177777888\",\n",
        "            \"time_mentioned\": \"immediately\",\n",
        "            \"additional_details\": \"building tilting dangerously, people afraid to move\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ferry sinking 2 km off Batangas coast. 150 passengers, lifeboats deployed but rough seas. Coast Guard responding but need additional rescue vessels. Mayday call from Captain Rodriguez\",\n",
        "        \"reasoning\": \"Maritime emergency with sinking ferry and large number of passengers. Rough seas complicate rescue. Coast Guard responding but additional resources needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"2 km off Batangas coast\",\n",
        "            \"disaster_type\": \"maritime emergency\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"150 passengers\",\n",
        "            \"specific_needs\": [\"additional rescue vessels\", \"maritime rescue coordination\"],\n",
        "            \"contact_info\": \"Captain Rodriguez (Mayday call)\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"lifeboats deployed, rough seas, Coast Guard responding\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Power plant explosion in Batangas. Evacuation radius 5km. 2000 residents affected, radiation leak suspected. Need hazmat and medical teams. Contact: Plant Director Santos 555-0600\",\n",
        "        \"reasoning\": \"Power plant explosion with suspected radiation leak requiring large evacuation radius. Large population affected with potential radiation exposure requiring specialized response.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Power plant in Batangas\",\n",
        "            \"disaster_type\": \"industrial explosion\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"2000 residents\",\n",
        "            \"specific_needs\": [\"hazmat teams\", \"radiation monitoring\", \"mass evacuation\", \"medical screening\"],\n",
        "            \"contact_info\": \"Plant Director Santos 555-0600\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"5km evacuation radius, radiation leak suspected\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Train derailment in Cabanatuan. Passenger train carrying 200 people. 15 injured, several carriages overturned. Medical triage needed on site. Contact: Station Master Lopez 09155555999\",\n",
        "        \"reasoning\": \"Train derailment with significant casualties and overturned carriages. Large number of passengers with injuries requiring on-site medical triage and evacuation.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Cabanatuan\",\n",
        "            \"disaster_type\": \"train derailment\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"200 passengers, 15 injured\",\n",
        "            \"specific_needs\": [\"medical triage\", \"heavy lifting equipment\", \"mass casualty response\"],\n",
        "            \"contact_info\": \"Station Master Lopez 09155555999\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"several carriages overturned\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Volcanic ash cloud from Mayon affecting flights. Airport closed, 500 passengers stranded. Respiratory problems reported. Need air quality monitoring and medical support. Contact: Airport Manager Cruz 555-0700\",\n",
        "        \"reasoning\": \"Volcanic emergency affecting air travel with health implications. Large number of stranded passengers with respiratory issues requiring medical attention and air quality assessment.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Airport near Mayon volcano\",\n",
        "            \"disaster_type\": \"volcanic activity\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"500 stranded passengers\",\n",
        "            \"specific_needs\": [\"air quality monitoring\", \"medical support\", \"passenger accommodation\"],\n",
        "            \"contact_info\": \"Airport Manager Cruz 555-0700\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"flights grounded, respiratory problems reported\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"High-rise fire in Ortigas business district. 30th floor engulfed, people trapped on upper floors. Ladder trucks can't reach. Need helicopter rescue. Fire Chief Hernandez 555-0800\",\n",
        "        \"reasoning\": \"High-rise fire with people trapped above ladder truck reach. Helicopter rescue needed for upper floor evacuation. Business district location indicates potential for many casualties.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"High-rise building, Ortigas business district\",\n",
        "            \"disaster_type\": \"high-rise fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"people trapped on upper floors\",\n",
        "            \"specific_needs\": [\"helicopter rescue\", \"aerial firefighting\"],\n",
        "            \"contact_info\": \"Fire Chief Hernandez 555-0800\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"30th floor engulfed, ladder trucks can't reach\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"School bus accident in Nueva Ecija. Bus overturned with 35 students inside. 8 children injured, driver unconscious. Need pediatric medical team and ambulances. Teacher Sarah 09166666777\",\n",
        "        \"reasoning\": \"School bus accident with children as victims requiring specialized pediatric medical care. Driver unconscious indicates serious accident with multiple casualties needing immediate attention.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Nueva Ecija\",\n",
        "            \"disaster_type\": \"vehicle accident\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"35 students, 8 injured, driver unconscious\",\n",
        "            \"specific_needs\": [\"pediatric medical team\", \"multiple ambulances\", \"trauma care\"],\n",
        "            \"contact_info\": \"Teacher Sarah 09166666777\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"school bus overturned\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Apartment building fire in Quezon City. 60 units, smoke spreading fast. Elderly and disabled residents need assistance evacuating from 4th floor. Contact: Building Admin Torres 555-0900\",\n",
        "        \"reasoning\": \"Apartment fire with vulnerable populations (elderly and disabled) needing evacuation assistance. Large building with many units and fast-spreading smoke creates urgent situation.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Apartment building, Quezon City\",\n",
        "            \"disaster_type\": \"apartment fire\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"elderly and disabled residents, 60 units total\",\n",
        "            \"specific_needs\": [\"evacuation assistance\", \"smoke ventilation\", \"medical support\"],\n",
        "            \"contact_info\": \"Building Admin Torres 555-0900\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"4th floor, smoke spreading fast\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Chlorine gas leak at swimming pool facility in Pasig. 25 people experiencing breathing difficulties. Pool area evacuated but gas spreading to nearby mall. Hazmat team urgent. Manager Wilson 09133333444\",\n",
        "        \"reasoning\": \"Chemical gas leak with people experiencing symptoms and gas spreading to populated area (mall). Hazmat response needed urgently to prevent wider exposure.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Swimming pool facility in Pasig\",\n",
        "            \"disaster_type\": \"chemical leak\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"25 people with breathing difficulties\",\n",
        "            \"specific_needs\": [\"hazmat team\", \"medical treatment\", \"area evacuation\"],\n",
        "            \"contact_info\": \"Manager Wilson 09133333444\",\n",
        "            \"time_mentioned\": \"urgent\",\n",
        "            \"additional_details\": \"chlorine gas spreading to nearby mall\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Fishing boat capsized near Palawan. 8 fishermen in water for 3 hours. Life jackets available but hypothermia setting in. Coast Guard helicopter dispatched. Contact: Harbor Master Diego 555-1000\",\n",
        "        \"reasoning\": \"Maritime emergency with people in water for extended time. Hypothermia risk makes this time-critical. Coast Guard responding but situation deteriorating.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Waters near Palawan\",\n",
        "            \"disaster_type\": \"maritime emergency\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"8 fishermen\",\n",
        "            \"specific_needs\": [\"water rescue\", \"medical treatment for hypothermia\"],\n",
        "            \"contact_info\": \"Harbor Master Diego 555-1000\",\n",
        "            \"time_mentioned\": \"3 hours in water\",\n",
        "            \"additional_details\": \"hypothermia setting in, Coast Guard helicopter dispatched\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Shopping mall roof collapse in Cebu. Christmas shoppers trapped underneath. Estimated 40 people in affected area. Heavy concrete slabs, need specialized lifting equipment. Mall Security Chief Tan 09144444555\",\n",
        "        \"reasoning\": \"Structural collapse in crowded public space with people trapped under heavy debris. Christmas shopping indicates high occupancy. Specialized equipment needed for concrete removal.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Shopping mall in Cebu\",\n",
        "            \"disaster_type\": \"structural collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"estimated 40 people trapped\",\n",
        "            \"specific_needs\": [\"specialized lifting equipment\", \"technical rescue\", \"medical triage\"],\n",
        "            \"contact_info\": \"Mall Security Chief Tan 09144444555\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"Christmas shoppers, heavy concrete slabs\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Helicopter crashed in rice field in Pangasinan. 4 crew members, aircraft on fire. Fuel spreading, risk of explosion. Fire department en route but need foam suppression. Pilot radioed position before crash. Air Traffic Control 555-1100\",\n",
        "        \"reasoning\": \"Aircraft crash with fire and explosion risk. Crew members at risk with spreading fuel creating dangerous situation. Specialized firefighting foam needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Rice field in Pangasinan\",\n",
        "            \"disaster_type\": \"aircraft crash\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"4 crew members\",\n",
        "            \"specific_needs\": [\"foam suppression\", \"aircraft rescue firefighting\", \"medical evacuation\"],\n",
        "            \"contact_info\": \"Air Traffic Control 555-1100\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"aircraft on fire, fuel spreading, explosion risk\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Toxic waste spill on highway in Cavite. Truck overturned carrying industrial chemicals. 2km traffic jam, people feeling sick from fumes. Need evacuation and decontamination. Environmental Officer Ramos 09199999000\",\n",
        "        \"reasoning\": \"Hazardous material spill affecting highway with people experiencing symptoms from toxic exposure. Large area affected with traffic backup requiring evacuation and specialized cleanup.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Highway in Cavite\",\n",
        "            \"disaster_type\": \"hazmat spill\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"people in 2km traffic jam feeling sick\",\n",
        "            \"specific_needs\": [\"area evacuation\", \"decontamination\", \"medical screening\", \"hazmat cleanup\"],\n",
        "            \"contact_info\": \"Environmental Officer Ramos 09199999000\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"industrial chemicals, people feeling sick from fumes\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Elderly care home flooded in Marikina. 45 senior residents, several bedridden. Water rising to second floor. Staff overwhelmed, need immediate rescue and medical support. Nurse Coordinator Santos 555-1200\",\n",
        "        \"reasoning\": \"Flood affecting vulnerable elderly population with bedridden patients. Water reaching second floor with overwhelmed staff creates critical evacuation needs with medical complications.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Elderly care home in Marikina\",\n",
        "            \"disaster_type\": \"flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"45 senior residents, several bedridden\",\n",
        "            \"specific_needs\": [\"water rescue\", \"medical support\", \"specialized evacuation\"],\n",
        "            \"contact_info\": \"Nurse Coordinator Santos 555-1200\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"water rising to second floor, staff overwhelmed\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Construction crane collapsed in Makati CBD. Crane arm fell across 3 buildings. 12 workers missing, office building damaged. Need urban search and rescue. Site Supervisor Garcia 09177775555\",\n",
        "        \"reasoning\": \"Construction accident affecting multiple buildings in business district. Missing workers and building damage require specialized urban search and rescue capabilities.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Makati CBD\",\n",
        "            \"disaster_type\": \"construction accident\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"12 workers missing\",\n",
        "            \"specific_needs\": [\"urban search and rescue\", \"heavy lifting equipment\", \"structural assessment\"],\n",
        "            \"contact_info\": \"Site Supervisor Garcia 09177775555\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"crane arm fell across 3 buildings\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Food poisoning outbreak at wedding reception in Laguna. 120 guests affected, 30 hospitalized with severe symptoms. Need mass casualty medical response. Event Coordinator Luna 555-1300\",\n",
        "        \"reasoning\": \"Mass casualty event from food poisoning with large number affected and many requiring hospitalization. Requires coordinated medical response for multiple patients.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Wedding reception venue in Laguna\",\n",
        "            \"disaster_type\": \"mass food poisoning\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"120 guests affected, 30 hospitalized\",\n",
        "            \"specific_needs\": [\"mass casualty medical response\", \"hospital coordination\", \"epidemiological investigation\"],\n",
        "            \"contact_info\": \"Event Coordinator Luna 555-1300\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"wedding reception, severe symptoms\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Cable car stuck halfway up mountain in Baguio. 15 tourists trapped 200 meters above ground. Strong winds preventing helicopter rescue. Need technical mountain rescue team. Tourism Officer Valdez 09188883333\",\n",
        "        \"reasoning\": \"Cable car emergency with tourists trapped at significant height. Weather conditions preventing air rescue requiring specialized mountain rescue techniques.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Mountain cable car in Baguio\",\n",
        "            \"disaster_type\": \"cable car emergency\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"15 tourists\",\n",
        "            \"specific_needs\": [\"technical mountain rescue\", \"rope rescue equipment\"],\n",
        "            \"contact_info\": \"Tourism Officer Valdez 09188883333\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"200 meters above ground, strong winds preventing helicopter rescue\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ammonia leak at ice plant in Bulacan. 6 workers overcome by fumes, 2 unconscious. Leak getting worse, need to evacuate 500m radius. Hazmat suits required. Plant Manager Cruz 555-1400\",\n",
        "        \"reasoning\": \"Industrial chemical leak with workers overcome by toxic fumes and expanding danger zone. Unconscious workers and worsening leak make this critical with evacuation needs.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Ice plant in Bulacan\",\n",
        "            \"disaster_type\": \"chemical leak\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"6 workers overcome, 2 unconscious, residents in 500m radius\",\n",
        "            \"specific_needs\": [\"hazmat response\", \"medical treatment\", \"area evacuation\"],\n",
        "            \"contact_info\": \"Plant Manager Cruz 555-1400\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"ammonia leak worsening, 500m evacuation radius\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Tourist boat engine fire in Boracay waters. 35 passengers evacuated to life rafts. Boat listing badly, may sink. Sea conditions rough. Need immediate water rescue. Boat Captain Fernandez via radio\",\n",
        "        \"reasoning\": \"Maritime emergency with boat fire and passengers in life rafts. Rough sea conditions and sinking vessel create critical rescue situation.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Boracay waters\",\n",
        "            \"disaster_type\": \"maritime fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"35 passengers in life rafts\",\n",
        "            \"specific_needs\": [\"water rescue\", \"marine firefighting\"],\n",
        "            \"contact_info\": \"Boat Captain Fernandez (via radio)\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"boat listing badly, rough sea conditions\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Elementary school wall collapsed during recess in Tarlac. 8 children trapped under rubble, 15 injured. School nurse treating wounded. Need pediatric trauma team and rescue equipment. Principal Martinez 09155557777\",\n",
        "        \"reasoning\": \"School accident with children trapped and injured during recess. Pediatric casualties require specialized medical care and rescue operations in school setting.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Elementary school in Tarlac\",\n",
        "            \"disaster_type\": \"structural collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"8 children trapped, 15 injured\",\n",
        "            \"specific_needs\": [\"pediatric trauma team\", \"rescue equipment\", \"family notification\"],\n",
        "            \"contact_info\": \"Principal Martinez 09155557777\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"wall collapsed during recess, school nurse treating wounded\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Propane tank explosion at restaurant in Antipolo. Building facade blown out, 4 diners critically burned. Gas leak continues, fire spreading to adjacent shops. Fire Chief Rodriguez 555-1500\",\n",
        "        \"reasoning\": \"Gas explosion with severe burn victims and continuing fire/gas hazard. Adjacent building involvement creates expanding emergency requiring firefighting and medical response.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Restaurant in Antipolo\",\n",
        "            \"disaster_type\": \"gas explosion\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"4 diners critically burned\",\n",
        "            \"specific_needs\": [\"burn trauma care\", \"gas leak control\", \"fire suppression\"],\n",
        "            \"contact_info\": \"Fire Chief Rodriguez 555-1500\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"building facade blown out, fire spreading to adjacent shops\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Flash flood trapped 25 hikers in Rizal canyon. Water level rising rapidly, hikers on ledge 50 feet above normal river level. Rappelling rescue needed urgently. Guide Marco 09122228888\",\n",
        "        \"reasoning\": \"Flash flood with hikers trapped in canyon requiring technical rope rescue. Rising water and remote location make this time-critical with specialized rescue needs.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Canyon in Rizal\",\n",
        "            \"disaster_type\": \"flash flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"25 hikers\",\n",
        "            \"specific_needs\": [\"rappelling rescue\", \"swift water rescue\", \"technical rope team\"],\n",
        "            \"contact_info\": \"Guide Marco 09122228888\",\n",
        "            \"time_mentioned\": \"urgently\",\n",
        "            \"additional_details\": \"on ledge 50 feet above normal river level, water rising rapidly\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567\",\n",
        "        \"reasoning\": \"This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Downtown Manila\",\n",
        "            \"disaster_type\": \"flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"15 families\",\n",
        "            \"specific_needs\": [\"rescue boats\"],\n",
        "            \"contact_info\": \"Maria 09171234567\",\n",
        "            \"time_mentioned\": \"urgent\",\n",
        "            \"additional_details\": \"families trapped on rooftops\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123.\",\n",
        "        \"reasoning\": \"This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"123 Oak Street\",\n",
        "            \"disaster_type\": \"house fire\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"2 elderly residents\",\n",
        "            \"specific_needs\": [\"evacuation assistance\"],\n",
        "            \"contact_info\": \"John 555-0123\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"elderly residents unable to evacuate alone\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP.\",\n",
        "        \"reasoning\": \"Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Kathmandu\",\n",
        "            \"disaster_type\": \"building collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"20 people trapped\",\n",
        "            \"specific_needs\": [\"heavy rescue equipment\", \"trained rescue personnel\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ASAP\",\n",
        "            \"additional_details\": \"voices heard from under debris\"\n",
        "        }\n",
        "    },\n",
        "     {\n",
        "        \"request\": \"URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567\",\n",
        "        \"reasoning\": \"This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Downtown Manila\",\n",
        "            \"disaster_type\": \"flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"15 families\",\n",
        "            \"specific_needs\": [\"rescue boats\"],\n",
        "            \"contact_info\": \"Maria 09171234567\",\n",
        "            \"time_mentioned\": \"urgent\",\n",
        "            \"additional_details\": \"families trapped on rooftops\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Typhoon approaching coastal villages in Leyte. 500+ residents need evacuation. Shelter required. Contact barangay captain 09998887766\",\n",
        "        \"reasoning\": \"Impending typhoon with large population at risk. Urgent evacuation needed before storm hits. Local official contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"coastal villages in Leyte\",\n",
        "            \"disaster_type\": \"typhoon\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"500+ residents\",\n",
        "            \"specific_needs\": [\"evacuation\", \"shelter\"],\n",
        "            \"contact_info\": \"barangay captain 09998887766\",\n",
        "            \"time_mentioned\": \"approaching\",\n",
        "            \"additional_details\": \"preemptive evacuation needed\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Earthquake 6.5 magnitude hit Central Luzon. Multiple buildings damaged. Casualties reported. Need medical teams.\",\n",
        "        \"reasoning\": \"Significant earthquake with structural damage and injuries. Immediate medical response required. No specific contact but clear need.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Central Luzon\",\n",
        "            \"disaster_type\": \"earthquake\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"multiple casualties\",\n",
        "            \"specific_needs\": [\"medical teams\", \"search and rescue\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent event\",\n",
        "            \"additional_details\": \"6.5 magnitude\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Landslide in Baguio along Kennon Road. 3 vehicles buried. Rescue ongoing but need heavy equipment.\",\n",
        "        \"reasoning\": \"Active landslide with vehicles trapped. Rescue in progress but requires additional resources.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Baguio along Kennon Road\",\n",
        "            \"disaster_type\": \"landslide\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"unknown (3 vehicles buried)\",\n",
        "            \"specific_needs\": [\"heavy equipment\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"rescue operations in progress\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Tsunami warning issued for Eastern Samar after 7.2 quake. Coastal evacuation needed immediately.\",\n",
        "        \"reasoning\": \"Potential tsunami threat requiring immediate coastal evacuation. No contact but clear action needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Eastern Samar\",\n",
        "            \"disaster_type\": \"tsunami warning\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"all coastal residents\",\n",
        "            \"specific_needs\": [\"evacuation coordination\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"immediately\",\n",
        "            \"additional_details\": \"triggered by 7.2 earthquake\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Drought in North Cotabato. Crops failing. 2000 families need food and water assistance. Contact LGU 088-1234567\",\n",
        "        \"reasoning\": \"Slow-onset disaster with humanitarian needs. Large population affected. Local government contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"North Cotabato\",\n",
        "            \"disaster_type\": \"drought\",\n",
        "            \"urgency_level\": \"medium\",\n",
        "            \"people_affected\": \"2000 families\",\n",
        "            \"specific_needs\": [\"food\", \"water\"],\n",
        "            \"contact_info\": \"LGU 088-1234567\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"crops failing\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Volcanic activity increasing at Mayon. 5km radius evacuation recommended. Need transportation for 800 families.\",\n",
        "        \"reasoning\": \"Potential volcanic eruption requiring preemptive evacuation. Specific zone and population identified.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Mayon volcano area\",\n",
        "            \"disaster_type\": \"volcanic activity\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"800 families\",\n",
        "            \"specific_needs\": [\"transportation\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"increasing activity\",\n",
        "            \"additional_details\": \"5km radius evacuation zone\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Wildfire spreading in California hills. 50 homes evacuated. Need air support. Contact fire chief 555-7890\",\n",
        "        \"reasoning\": \"Active wildfire with evacuations in progress. Specialized firefighting equipment needed. Direct contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"California hills\",\n",
        "            \"disaster_type\": \"wildfire\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"50 homes evacuated\",\n",
        "            \"specific_needs\": [\"air support\"],\n",
        "            \"contact_info\": \"fire chief 555-7890\",\n",
        "            \"time_mentioned\": \"spreading\",\n",
        "            \"additional_details\": \"evacuations in progress\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Hailstorm damaged crops in Kansas. 150 farmers affected. Need damage assessment and relief.\",\n",
        "        \"reasoning\": \"Agricultural disaster with economic impact. Assessment needed to determine relief requirements.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Kansas\",\n",
        "            \"disaster_type\": \"hailstorm\",\n",
        "            \"urgency_level\": \"medium\",\n",
        "            \"people_affected\": \"150 farmers\",\n",
        "            \"specific_needs\": [\"damage assessment\", \"agricultural relief\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent event\",\n",
        "            \"additional_details\": \"crop damage\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Blizzard conditions in Minnesota. Stranded motorists on I-35. Need rescue and warming shelters.\",\n",
        "        \"reasoning\": \"Winter emergency with people stranded. Dual need for rescue and shelter from extreme cold.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Minnesota, I-35\",\n",
        "            \"disaster_type\": \"blizzard\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"stranded motorists\",\n",
        "            \"specific_needs\": [\"rescue\", \"warming shelters\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"current conditions\",\n",
        "            \"additional_details\": \"highway stranded\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Tornado touched down in Oklahoma City suburbs. Multiple homes destroyed. Need search teams and medical.\",\n",
        "        \"reasoning\": \"Destructive tornado with structural damage. Immediate search and medical response required.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Oklahoma City suburbs\",\n",
        "            \"disaster_type\": \"tornado\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"unknown (multiple homes)\",\n",
        "            \"specific_needs\": [\"search teams\", \"medical assistance\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent touchdown\",\n",
        "            \"additional_details\": \"homes destroyed\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Heat wave in Delhi. 12 dead from heatstroke. Need water distribution and cooling centers.\",\n",
        "        \"reasoning\": \"Public health emergency from extreme heat. Preventive measures needed to protect population.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Delhi\",\n",
        "            \"disaster_type\": \"heat wave\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"population at risk (12 dead)\",\n",
        "            \"specific_needs\": [\"water distribution\", \"cooling centers\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"fatalities reported\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Avalanche in Swiss Alps. Ski lodge buried. 30 tourists missing. International rescue requested.\",\n",
        "        \"reasoning\": \"Mountain disaster with international tourists involved. Requires specialized alpine rescue.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Swiss Alps\",\n",
        "            \"disaster_type\": \"avalanche\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"30 tourists missing\",\n",
        "            \"specific_needs\": [\"alpine rescue teams\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent event\",\n",
        "            \"additional_details\": \"ski lodge buried\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Sinkhole opened in downtown Guatemala City. 3 buildings at risk. Need structural engineers.\",\n",
        "        \"reasoning\": \"Geological event threatening structures. Requires technical assessment to prevent further damage.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"downtown Guatemala City\",\n",
        "            \"disaster_type\": \"sinkhole\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"building occupants\",\n",
        "            \"specific_needs\": [\"structural engineers\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent occurrence\",\n",
        "            \"additional_details\": \"3 buildings threatened\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Monsoon rains caused severe flooding in Mumbai. Thousands stranded. Need food and water drops.\",\n",
        "        \"reasoning\": \"Large-scale urban flooding with basic needs required. Aerial delivery may be necessary.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Mumbai\",\n",
        "            \"disaster_type\": \"flood\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"thousands\",\n",
        "            \"specific_needs\": [\"food\", \"water\", \"aerial delivery\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"monsoon-related\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Industrial/Technological Disasters (16-30)\n",
        "    {\n",
        "        \"request\": \"Chemical plant explosion in Texas. Toxic cloud moving east. Evacuate 10km radius. Call EPA hotline 800-1234567\",\n",
        "        \"reasoning\": \"Hazmat emergency with environmental health risk. Specific evacuation zone and official contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Texas (chemical plant)\",\n",
        "            \"disaster_type\": \"industrial explosion\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"10km radius population\",\n",
        "            \"specific_needs\": [\"evacuation\", \"hazmat response\"],\n",
        "            \"contact_info\": \"EPA hotline 800-1234567\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"toxic cloud present\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Nuclear power plant cooling system failure in Japan. Potential radiation leak. Prepare for evacuation.\",\n",
        "        \"reasoning\": \"Potential nuclear incident requiring preparedness. No contact but clear risk described.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Japan (nuclear plant)\",\n",
        "            \"disaster_type\": \"nuclear incident\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"nearby residents\",\n",
        "            \"specific_needs\": [\"evacuation prep\", \"radiation monitoring\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"potential threat\",\n",
        "            \"additional_details\": \"cooling system failure\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Oil pipeline rupture in Alberta. 1000+ barrels spilled into river. Need containment and cleanup crews.\",\n",
        "        \"reasoning\": \"Environmental disaster with water contamination. Specialized cleanup response required.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Alberta\",\n",
        "            \"disaster_type\": \"oil spill\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"environmental impact\",\n",
        "            \"specific_needs\": [\"containment\", \"cleanup crews\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent rupture\",\n",
        "            \"additional_details\": \"river contamination\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Train derailment carrying hazardous materials in Ohio. 2 mile evacuation ordered. Call 911 for assistance.\",\n",
        "        \"reasoning\": \"Transportation hazmat incident with evacuation order. Emergency services contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Ohio (train derailment)\",\n",
        "            \"disaster_type\": \"hazmat incident\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"2 mile radius\",\n",
        "            \"specific_needs\": [\"evacuation\", \"hazmat response\"],\n",
        "            \"contact_info\": \"911\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"hazardous materials involved\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Factory fire in Bangladesh. Workers trapped on upper floors. Need high ladder trucks. Contact local fire 999\",\n",
        "        \"reasoning\": \"Industrial fire with trapped victims. Specialized fire equipment needed. Local emergency number provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Bangladesh (factory)\",\n",
        "            \"disaster_type\": \"industrial fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"trapped workers\",\n",
        "            \"specific_needs\": [\"high ladder trucks\"],\n",
        "            \"contact_info\": \"local fire 999\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"upper floors inaccessible\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Dam failure warning in Laos. Downstream villages must evacuate immediately. Use evacuation routes posted.\",\n",
        "        \"reasoning\": \"Potential catastrophic flooding from infrastructure failure. Clear instructions given despite no contact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Laos (downstream villages)\",\n",
        "            \"disaster_type\": \"dam failure\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"downstream population\",\n",
        "            \"specific_needs\": [\"immediate evacuation\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"immediately\",\n",
        "            \"additional_details\": \"posted routes available\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Mine collapse in Chile. 12 miners unaccounted for. Need specialized rescue teams with cave-in experience.\",\n",
        "        \"reasoning\": \"Underground emergency requiring specialized mining rescue expertise. Specific number of victims provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Chile (mine)\",\n",
        "            \"disaster_type\": \"mine collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"12 miners missing\",\n",
        "            \"specific_needs\": [\"mine rescue teams\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent collapse\",\n",
        "            \"additional_details\": \"cave-in conditions\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Gas leak in apartment complex in Seoul. 50 residents complaining of nausea. Need hazmat and medical.\",\n",
        "        \"reasoning\": \"Building hazmat situation with health symptoms reported. Dual response needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Seoul (apartment complex)\",\n",
        "            \"disaster_type\": \"gas leak\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"50 residents\",\n",
        "            \"specific_needs\": [\"hazmat\", \"medical\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"nausea symptoms\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Power grid failure across Michigan. Hospitals on backup generators. Need repair crews and fuel deliveries.\",\n",
        "        \"reasoning\": \"Infrastructure failure affecting critical facilities. Multiple resource needs identified.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Michigan\",\n",
        "            \"disaster_type\": \"power outage\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"regional population\",\n",
        "            \"specific_needs\": [\"repair crews\", \"generator fuel\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"hospitals affected\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Water treatment plant contamination in Nairobi. Boil water notice for entire city. Need water distribution.\",\n",
        "        \"reasoning\": \"Public health infrastructure failure requiring alternative water sources.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Nairobi\",\n",
        "            \"disaster_type\": \"water contamination\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"city population\",\n",
        "            \"specific_needs\": [\"water distribution\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"boil notice issued\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Airplane crash in residential area of Jakarta. 50 houses damaged. Need fire suppression and triage.\",\n",
        "        \"reasoning\": \"Transportation disaster with secondary impacts. Immediate fire and medical response required.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Jakarta (residential area)\",\n",
        "            \"disaster_type\": \"plane crash\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"residents (50 houses)\",\n",
        "            \"specific_needs\": [\"fire suppression\", \"medical triage\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent crash\",\n",
        "            \"additional_details\": \"residential impact\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ship collision in Suez Canal. Oil tanker leaking. Need containment booms and cleanup. Contact port authority.\",\n",
        "        \"reasoning\": \"Maritime environmental emergency requiring specialized equipment. Relevant authority identified.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Suez Canal\",\n",
        "            \"disaster_type\": \"maritime spill\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"environmental impact\",\n",
        "            \"specific_needs\": [\"containment booms\", \"cleanup\"],\n",
        "            \"contact_info\": \"port authority\",\n",
        "            \"time_mentioned\": \"ongoing leak\",\n",
        "            \"additional_details\": \"tanker involved\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Bridge collapse in Genoa. Vehicles in water. Need dive teams and cranes. Call emergency +39 1234567\",\n",
        "        \"reasoning\": \"Infrastructure failure with victims in water. Specialized rescue equipment needed. International contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Genoa (bridge)\",\n",
        "            \"disaster_type\": \"bridge collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"motorists in water\",\n",
        "            \"specific_needs\": [\"dive teams\", \"cranes\"],\n",
        "            \"contact_info\": \"+39 1234567\",\n",
        "            \"time_mentioned\": \"recent collapse\",\n",
        "            \"additional_details\": \"vehicles submerged\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Cyberattack on hospital systems in London. Patient records inaccessible. Need IT security teams immediately.\",\n",
        "        \"reasoning\": \"Technological disaster impacting healthcare. Specialized IT response required urgently.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"London (hospitals)\",\n",
        "            \"disaster_type\": \"cyberattack\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"hospital operations\",\n",
        "            \"specific_needs\": [\"IT security teams\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"patient records affected\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ferry capsized in Philippines waters. 120 passengers. Need coast guard and rescue boats. Contact PCG 0917-1234567\",\n",
        "        \"reasoning\": \"Maritime disaster with many passengers. Coast guard coordination needed. Direct contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Philippines waters\",\n",
        "            \"disaster_type\": \"ferry accident\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"120 passengers\",\n",
        "            \"specific_needs\": [\"coast guard\", \"rescue boats\"],\n",
        "            \"contact_info\": \"PCG 0917-1234567\",\n",
        "            \"time_mentioned\": \"recent capsizing\",\n",
        "            \"additional_details\": \"mass rescue needed\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Humanitarian Crises (31-45)\n",
        "    {\n",
        "        \"request\": \"Refugee camp in Jordan overwhelmed. 5000 new arrivals. Need tents, food, and medical supplies.\",\n",
        "        \"reasoning\": \"Humanitarian crisis with basic needs requirements. Large population affected.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Jordan (refugee camp)\",\n",
        "            \"disaster_type\": \"refugee crisis\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"5000 new arrivals\",\n",
        "            \"specific_needs\": [\"tents\", \"food\", \"medical supplies\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"camp overwhelmed\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Cholera outbreak in Yemen. 200 cases reported. Need clean water and medical teams. Contact WHO rep.\",\n",
        "        \"reasoning\": \"Disease outbreak requiring medical and sanitation response. International organization contact available.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Yemen\",\n",
        "            \"disaster_type\": \"disease outbreak\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"200 cases\",\n",
        "            \"specific_needs\": [\"clean water\", \"medical teams\"],\n",
        "            \"contact_info\": \"WHO representative\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"cholera confirmed\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Food shortage in South Sudan. Children malnourished. Need emergency feeding program. Call UNICEF 123456\",\n",
        "        \"reasoning\": \"Famine conditions with vulnerable population affected. Specific program need and contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"South Sudan\",\n",
        "            \"disaster_type\": \"famine\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"malnourished children\",\n",
        "            \"specific_needs\": [\"feeding program\"],\n",
        "            \"contact_info\": \"UNICEF 123456\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"acute malnutrition\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ethnic violence in Myanmar. 3000 displaced. Need protected shelter and peacekeeping. Contact ICRC.\",\n",
        "        \"reasoning\": \"Conflict situation creating displaced persons. Need for both humanitarian aid and security.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Myanmar\",\n",
        "            \"disaster_type\": \"civil conflict\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"3000 displaced\",\n",
        "            \"specific_needs\": [\"protected shelter\", \"peacekeeping\"],\n",
        "            \"contact_info\": \"ICRC\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"ethnic violence\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Human trafficking victims found in warehouse in Malaysia. 87 people need medical and shelter. Call police hotline.\",\n",
        "        \"reasoning\": \"Crime-related humanitarian crisis. Vulnerable population needing protection and care. Official contact available.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Malaysia (warehouse)\",\n",
        "            \"disaster_type\": \"human trafficking\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"87 victims\",\n",
        "            \"specific_needs\": [\"medical\", \"shelter\"],\n",
        "            \"contact_info\": \"police hotline\",\n",
        "            \"time_mentioned\": \"recent discovery\",\n",
        "            \"additional_details\": \"warehouse location\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Drought in Somalia causing mass migration. 10000 heading to camps. Need water and registration system.\",\n",
        "        \"reasoning\": \"Climate-related migration crisis. Large population movement requiring both supplies and management.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Somalia\",\n",
        "            \"disaster_type\": \"drought migration\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"10000 migrating\",\n",
        "            \"specific_needs\": [\"water\", \"registration system\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"mass movement\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Earthquake survivors in Nepal still without shelter after 2 weeks. 500 families need tents before winter.\",\n",
        "        \"reasoning\": \"Protracted disaster situation with seasonal urgency. Specific need and timeframe provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Nepal\",\n",
        "            \"disaster_type\": \"earthquake aftermath\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"500 families\",\n",
        "            \"specific_needs\": [\"tents\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"2 weeks post-event\",\n",
        "            \"additional_details\": \"winter approaching\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Rohingya refugee children in Bangladesh need education supplies. 3000 students without materials. Contact Save the Children.\",\n",
        "        \"reasoning\": \"Long-term humanitarian need for education. Specific population and organization contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Bangladesh (refugee camps)\",\n",
        "            \"disaster_type\": \"education emergency\",\n",
        "            \"urgency_level\": \"medium\",\n",
        "            \"people_affected\": \"3000 students\",\n",
        "            \"specific_needs\": [\"education supplies\"],\n",
        "            \"contact_info\": \"Save the Children\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"Rohingya children\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Winter storm left homeless population in Moscow at risk. Need warming centers and coats. Call city services.\",\n",
        "        \"reasoning\": \"Vulnerable population at risk from weather. Basic protection needs with local authority contact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Moscow\",\n",
        "            \"disaster_type\": \"winter emergency\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"homeless population\",\n",
        "            \"specific_needs\": [\"warming centers\", \"coats\"],\n",
        "            \"contact_info\": \"city services\",\n",
        "            \"time_mentioned\": \"post-storm\",\n",
        "            \"additional_details\": \"extreme cold risk\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Ebola cases reported in Uganda border region. Need quarantine supplies and contact tracing. Contact Ministry of Health.\",\n",
        "        \"reasoning\": \"High-risk disease outbreak requiring specialized response. Government health authority contact provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Uganda border region\",\n",
        "            \"disaster_type\": \"ebola outbreak\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"population at risk\",\n",
        "            \"specific_needs\": [\"quarantine supplies\", \"contact tracing\"],\n",
        "            \"contact_info\": \"Ministry of Health\",\n",
        "            \"time_mentioned\": \"recent cases\",\n",
        "            \"additional_details\": \"border area\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Child soldiers rescued in Congo. 45 need trauma counseling and reintegration. Call UNICEF specialist.\",\n",
        "        \"reasoning\": \"Specialized humanitarian case requiring psychological and social services. UN agency contact available.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Congo\",\n",
        "            \"disaster_type\": \"child soldiers\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"45 children\",\n",
        "            \"specific_needs\": [\"trauma counseling\", \"reintegration\"],\n",
        "            \"contact_info\": \"UNICEF specialist\",\n",
        "            \"time_mentioned\": \"recent rescue\",\n",
        "            \"additional_details\": \"former combatants\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"HIV medication shortage in Zimbabwe. 1200 patients at risk. Need emergency shipment. Contact MSF clinic.\",\n",
        "        \"reasoning\": \"Medical supply crisis for chronic condition. Specific medication need and medical organization contact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Zimbabwe\",\n",
        "            \"disaster_type\": \"medication shortage\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"1200 patients\",\n",
        "            \"specific_needs\": [\"HIV medications\"],\n",
        "            \"contact_info\": \"MSF clinic\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"life-threatening\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Post-hurricane mental health crisis in Puerto Rico. Suicide rates rising. Need crisis counselors.\",\n",
        "        \"reasoning\": \"Secondary disaster impact requiring mental health response. Statistical evidence of need provided.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Puerto Rico\",\n",
        "            \"disaster_type\": \"mental health crisis\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"population affected\",\n",
        "            \"specific_needs\": [\"crisis counselors\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"post-hurricane\",\n",
        "            \"additional_details\": \"suicide increase\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Gender-based violence increasing in Syrian refugee camps. Need safe spaces and legal aid. Contact UNHCR.\",\n",
        "        \"reasoning\": \"Protection crisis within displaced population. Specialized services needed with UN contact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Syrian refugee camps\",\n",
        "            \"disaster_type\": \"protection crisis\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"women and girls\",\n",
        "            \"specific_needs\": [\"safe spaces\", \"legal aid\"],\n",
        "            \"contact_info\": \"UNHCR\",\n",
        "            \"time_mentioned\": \"increasing trend\",\n",
        "            \"additional_details\": \"gender-based violence\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Disabled elderly abandoned during evacuation in Florida nursing home. Need specialized rescue. Call 911.\",\n",
        "        \"reasoning\": \"Vulnerable population left behind in disaster. Specialized rescue required with emergency contact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Florida nursing home\",\n",
        "            \"disaster_type\": \"abandoned patients\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"disabled elderly\",\n",
        "            \"specific_needs\": [\"specialized rescue\"],\n",
        "            \"contact_info\": \"911\",\n",
        "            \"time_mentioned\": \"during evacuation\",\n",
        "            \"additional_details\": \"nursing home\"\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Urban/Structural Disasters (46-60)\n",
        "    {\n",
        "        \"request\": \"House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123.\",\n",
        "        \"reasoning\": \"This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"123 Oak Street\",\n",
        "            \"disaster_type\": \"house fire\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"2 elderly residents\",\n",
        "            \"specific_needs\": [\"evacuation assistance\"],\n",
        "            \"contact_info\": \"John 555-0123\",\n",
        "            \"time_mentioned\": \"not specified\",\n",
        "            \"additional_details\": \"elderly residents unable to evacuate alone\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP.\",\n",
        "        \"reasoning\": \"Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Kathmandu\",\n",
        "            \"disaster_type\": \"building collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"20 people trapped\",\n",
        "            \"specific_needs\": [\"heavy rescue equipment\", \"trained rescue personnel\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ASAP\",\n",
        "            \"additional_details\": \"voices heard from under debris\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Apartment building fire in Dubai. 100+ residents on upper floors. Need aerial ladder and evacuation plan.\",\n",
        "        \"reasoning\": \"High-rise fire emergency with many residents at risk. Specialized firefighting and evacuation required.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Dubai (apartment building)\",\n",
        "            \"disaster_type\": \"high-rise fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"100+ residents\",\n",
        "            \"specific_needs\": [\"aerial ladder\", \"evacuation plan\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"upper floors at risk\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Subway tunnel flooding in New York. Train stranded with 200 passengers. Need pumps and rescue.\",\n",
        "        \"reasoning\": \"Transportation infrastructure failure with trapped passengers. Specialized equipment needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"New York (subway)\",\n",
        "            \"disaster_type\": \"tunnel flooding\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"200 passengers\",\n",
        "            \"specific_needs\": [\"pumps\", \"tunnel rescue\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"stranded train\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Elevator failure in Shanghai skyscraper. 15 people stuck between floors for 2 hours. Need technical rescue.\",\n",
        "        \"reasoning\": \"Mechanical failure in high-rise with trapped people. Duration increases urgency. Specialized rescue needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Shanghai (skyscraper)\",\n",
        "            \"disaster_type\": \"elevator failure\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"15 people trapped\",\n",
        "            \"specific_needs\": [\"technical rescue\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"2 hours duration\",\n",
        "            \"additional_details\": \"between floors\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Parking garage structural cracks in Toronto. Immediate evacuation needed. Engineers required for assessment.\",\n",
        "        \"reasoning\": \"Potential structural failure requiring precautionary evacuation. Technical assessment needed.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Toronto (parking garage)\",\n",
        "            \"disaster_type\": \"structural failure\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"occupants\",\n",
        "            \"specific_needs\": [\"structural engineers\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"immediate\",\n",
        "            \"additional_details\": \"visible cracks\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Stadium crowd crush during concert in London. Multiple injuries reported. Need mass casualty response.\",\n",
        "        \"reasoning\": \"Public gathering disaster with many injuries. Specialized medical response required.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"London (stadium)\",\n",
        "            \"disaster_type\": \"crowd disaster\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"multiple injuries\",\n",
        "            \"specific_needs\": [\"mass casualty response\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"during event\",\n",
        "            \"additional_details\": \"concert crowd\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Shopping mall roof collapse in Manila. 50+ shoppers trapped. Need shoring and careful extraction.\",\n",
        "        \"reasoning\": \"Commercial building failure with many victims. Technical rescue approach needed to prevent further collapse.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Manila (shopping mall)\",\n",
        "            \"disaster_type\": \"roof collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"50+ shoppers\",\n",
        "            \"specific_needs\": [\"structural shoring\", \"careful extraction\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent collapse\",\n",
        "            \"additional_details\": \"public space\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Hotel fire in Las Vegas. 300 guests need evacuation. Some wheelchair users on upper floors.\",\n",
        "        \"reasoning\": \"Mass occupancy fire with accessibility challenges. Large-scale evacuation with special considerations.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Las Vegas (hotel)\",\n",
        "            \"disaster_type\": \"hotel fire\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"300 guests\",\n",
        "            \"specific_needs\": [\"evacuation\", \"accessible rescue\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"ongoing\",\n",
        "            \"additional_details\": \"mobility-impaired guests\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"University lab explosion in Berlin. Chemical exposure reported. Need decontamination and hazmat.\",\n",
        "        \"reasoning\": \"Academic facility hazmat incident requiring specialized cleanup and medical response.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Berlin (university)\",\n",
        "            \"disaster_type\": \"lab accident\",\n",
        "            \"urgency_level\": \"high\",\n",
        "            \"people_affected\": \"lab occupants\",\n",
        "            \"specific_needs\": [\"decontamination\", \"hazmat\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent explosion\",\n",
        "            \"additional_details\": \"chemical exposure\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"request\": \"Construction crane collapse in Singapore. Fell across busy street. Casualties and traffic blocked.\",\n",
        "        \"reasoning\": \"Construction accident with both immediate casualties and transportation impact.\",\n",
        "        \"extraction\": {\n",
        "            \"location\": \"Singapore (construction site)\",\n",
        "            \"disaster_type\": \"crane collapse\",\n",
        "            \"urgency_level\": \"critical\",\n",
        "            \"people_affected\": \"unknown casualties\",\n",
        "            \"specific_needs\": [\"rescue\", \"traffic control\"],\n",
        "            \"contact_info\": \"not provided\",\n",
        "            \"time_mentioned\": \"recent collapse\",\n",
        "            \"additional_details\": \"public roadway impact\"\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "20z1RelRQp5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "# Prompt format\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a disaster response assistant. Extract structured information from disaster reports.\n",
        "\n",
        "Respond in this format:\n",
        "\n",
        "location: ...\n",
        "disaster_type: ...\n",
        "urgency_level: ...\n",
        "people_affected: ...\n",
        "specific_needs: ...\n",
        "contact_info: ...\n",
        "time_mentioned: ...\n",
        "additional_details: ...\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "\n",
        "{reasoning}\n",
        "\n",
        "\n",
        "{answer}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    # Example for extracting the content between <answer>...</answer>\n",
        "    match = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
        "    return match.group(1).strip() if match else \"\"\n",
        "\n",
        "\n",
        "# Main dataset loader\n",
        "def get_disaster_dataset() -> Dataset:\n",
        "    entries = []\n",
        "    for sample in disaster_samples:\n",
        "        reasoning = sample[\"reasoning\"]\n",
        "        answer = sample[\"extraction\"]\n",
        "        answer_str = \"\\n\".join(f\"{k}: {v}\" for k, v in answer.items())\n",
        "        prompt = [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": sample[\"request\"]}\n",
        "        ]\n",
        "        full_answer = XML_COT_FORMAT.format(reasoning=reasoning, answer=answer_str)\n",
        "        entries.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"answer\": full_answer\n",
        "        })\n",
        "    return Dataset.from_list(entries)\n",
        "\n",
        "# Now you can use this in your training loop\n",
        "dataset = get_disaster_dataset()"
      ],
      "metadata": {
        "id": "3KVmoij3HGoH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    pattern = r\"^\\n.*?\\n\\n\\n.*?\\n\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r, re.DOTALL) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    pattern = r\".*?\\s*.*?\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r, re.DOTALL) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]\n",
        "\n"
      ],
      "metadata": {
        "id": "YhcQ5h7EIZGv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import GRPOConfig\n",
        "from torch.cuda import is_bf16_supported\n",
        "\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm=False,  # ✅ Disable vLLM for fast local test unless needed\n",
        "    learning_rate=1e-5,  # Slightly higher for quick convergence\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.01,  # Lower for small test\n",
        "    warmup_ratio=0.0,  # Disable warmup for quick tests\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    optim=\"adamw_torch\",  # Simplest optimizer for tests\n",
        "    logging_steps=1,\n",
        "    bf16=is_bf16_supported(),\n",
        "    fp16=not is_bf16_supported(),\n",
        "\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "\n",
        "    num_generations=2,  # ✅ Reduce to save VRAM\n",
        "    max_prompt_length=128,  # Reduce for faster tokenization\n",
        "    max_completion_length=100,\n",
        "\n",
        "    max_steps=10,  # ✅ Only 10 steps for quick test\n",
        "    save_steps=10,\n",
        "    save_total_limit=1,  # Don’t clutter output dir\n",
        "    max_grad_norm=0.1,\n",
        "\n",
        "    report_to=\"none\",\n",
        "    output_dir=\"outputs/test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTvSuu_CIcp-",
        "outputId": "8a148b3b-4ea6-4171-df73-c762f511a04f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n"
      ],
      "metadata": {
        "id": "a6tRSMrVIetc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kx1v3pZxIiXy",
        "outputId": "0f54b6ed-12b0-4449-8df3-5abd8899290b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 3 | Num Epochs = 4 | Total steps = 10\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
            " \"-____-\"     Trainable parameters = 132,120,576/4,000,000,000 (3.30% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Question:\n",
            "House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123. \n",
            "Answer:\n",
            "\n",
            "This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\n",
            "\n",
            "\n",
            "location: 123 Oak Street\n",
            "disaster_type: house fire\n",
            "urgency_level: high\n",
            "people_affected: 2 elderly residents\n",
            "specific_needs: ['evacuation assistance']\n",
            "contact_info: John 555-0123\n",
            "time_mentioned: not specified\n",
            "additional_details: elderly residents unable to evacuate alone\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report about a house fire at 123 Oak Street. Two elderly residents need help evacuating, and there's a contact number: John 555-0123.\n",
            "\n",
            "First, I need to extract the structured information as per the given format. Let me go through each field.\n",
            "\n",
            "Location is straightforward: 123 Oak Street. Disaster type is a house fire. Urgency level should be high because it \n",
            "Extracted:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 02:19, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / xmlcount_reward_func / mean</th>\n",
              "      <th>rewards / xmlcount_reward_func / std</th>\n",
              "      <th>rewards / soft_format_reward_func / mean</th>\n",
              "      <th>rewards / soft_format_reward_func / std</th>\n",
              "      <th>rewards / strict_format_reward_func / mean</th>\n",
              "      <th>rewards / strict_format_reward_func / std</th>\n",
              "      <th>rewards / int_reward_func / mean</th>\n",
              "      <th>rewards / int_reward_func / std</th>\n",
              "      <th>rewards / correctness_reward_func / mean</th>\n",
              "      <th>rewards / correctness_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.014142</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.014142</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.514000</td>\n",
              "      <td>0.019799</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.019799</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380500</td>\n",
              "      <td>0.168999</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>-0.119500</td>\n",
              "      <td>0.168999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.534000</td>\n",
              "      <td>0.048083</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011946</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.048083</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.485500</td>\n",
              "      <td>0.020506</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>-0.014500</td>\n",
              "      <td>0.020506</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.546000</td>\n",
              "      <td>0.065054</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002479</td>\n",
              "      <td>0.046000</td>\n",
              "      <td>0.065054</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.515500</td>\n",
              "      <td>0.006364</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003337</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.006364</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.159099</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002707</td>\n",
              "      <td>-0.112500</td>\n",
              "      <td>0.159099</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Question:\n",
            "URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567 \n",
            "Answer:\n",
            "\n",
            "This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\n",
            "\n",
            "\n",
            "location: Downtown Manila\n",
            "disaster_type: flood\n",
            "urgency_level: critical\n",
            "people_affected: 15 families\n",
            "specific_needs: ['rescue boats']\n",
            "contact_info: Maria 09171234567\n",
            "time_mentioned: urgent\n",
            "additional_details: families trapped on rooftops\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's break down the user's message. The report says \"URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567\". \n",
            "\n",
            "First, I need to extract the structured information. The location is clearly Downtown Manila. The disaster type is a flood. The urgency level is urgent, so I'll note that. \n",
            "\n",
            "Next, the number of people affected \n",
            "Extracted:\n",
            "\n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "-------------------- Question:\n",
            "Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP. \n",
            "Answer:\n",
            "\n",
            "Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\n",
            "\n",
            "\n",
            "location: Kathmandu\n",
            "disaster_type: building collapse\n",
            "urgency_level: critical\n",
            "people_affected: 20 people trapped\n",
            "specific_needs: ['heavy rescue equipment', 'trained rescue personnel']\n",
            "contact_info: not provided\n",
            "time_mentioned: ASAP\n",
            "additional_details: voices heard from under debris\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report: \"Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP.\" I need to extract structured information from this.\n",
            "\n",
            "First, the location is clearly Kathmandu. Disaster type is a building collapse. Urgency level is high because they mention \"ASAP.\" People affected are 20. Specific needs are heavy rescue equipment. Contact info isn't mentioned, so \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123. \n",
            "Answer:\n",
            "\n",
            "This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\n",
            "\n",
            "\n",
            "location: 123 Oak Street\n",
            "disaster_type: house fire\n",
            "urgency_level: high\n",
            "people_affected: 2 elderly residents\n",
            "specific_needs: ['evacuation assistance']\n",
            "contact_info: John 555-0123\n",
            "time_mentioned: not specified\n",
            "additional_details: elderly residents unable to evacuate alone\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report about a house fire at 123 Oak Street. Two elderly residents need help evacuating, and there's a contact number: John 555-0123.\n",
            "\n",
            "First, I need to extract the structured information. The location is clearly 123 Oak Street. The disaster type is a house fire. The urgency level should be high since it's a fire, which is life-threatening. People affected \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP. \n",
            "Answer:\n",
            "\n",
            "Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\n",
            "\n",
            "\n",
            "location: Kathmandu\n",
            "disaster_type: building collapse\n",
            "urgency_level: critical\n",
            "people_affected: 20 people trapped\n",
            "specific_needs: ['heavy rescue equipment', 'trained rescue personnel']\n",
            "contact_info: not provided\n",
            "time_mentioned: ASAP\n",
            "additional_details: voices heard from under debris\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report: \"Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP.\"\n",
            "\n",
            "First, I need to extract structured information. Let's go through each part.\n",
            "\n",
            "Location: The report mentions Kathmandu, which is a city in Nepal. So location is Kathmandu, Nepal. But the user didn't specify the exact area. Maybe just Kathmandu.\n",
            "\n",
            "Disaster \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567 \n",
            "Answer:\n",
            "\n",
            "This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\n",
            "\n",
            "\n",
            "location: Downtown Manila\n",
            "disaster_type: flood\n",
            "urgency_level: critical\n",
            "people_affected: 15 families\n",
            "specific_needs: ['rescue boats']\n",
            "contact_info: Maria 09171234567\n",
            "time_mentioned: urgent\n",
            "additional_details: families trapped on rooftops\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report: \"URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567\". I need to extract structured information.\n",
            "\n",
            "First, the location is clearly Downtown Manila. The disaster type is a flood. The urgency level is URGENT as stated. People affected: 15 families. Specific needs mention rescue boats \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "URGENT: Flood in Downtown Manila. 15 families trapped on rooftops. Need rescue boats. Contact: Maria 09171234567 \n",
            "Answer:\n",
            "\n",
            "This is a flood emergency in Manila with people trapped. The urgency is critical given people are on rooftops. They need immediate rescue with boats. Contact information is provided.\n",
            "\n",
            "\n",
            "location: Downtown Manila\n",
            "disaster_type: flood\n",
            "urgency_level: critical\n",
            "people_affected: 15 families\n",
            "specific_needs: ['rescue boats']\n",
            "contact_info: Maria 09171234567\n",
            "time_mentioned: urgent\n",
            "additional_details: families trapped on rooftops\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's see. The user provided a disaster report about a flood in Downtown Manila. I need to extract the structured information as per the given format.\n",
            "\n",
            "First, the location is clearly \"Downtown Manila\". The disaster type is a flood. The urgency level is \"URGENT\" as stated at the beginning. The people affected are 15 families, so that's 15 families. Specific needs mention rescue boats, so that's under specific_needs. Contact info \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "House fire at 123 Oak Street. Two elderly residents need help evacuating. Call John 555-0123. \n",
            "Answer:\n",
            "\n",
            "This is a house fire with specific address. Two elderly people need evacuation help. Contact provided. High urgency due to fire and vulnerable population.\n",
            "\n",
            "\n",
            "location: 123 Oak Street\n",
            "disaster_type: house fire\n",
            "urgency_level: high\n",
            "people_affected: 2 elderly residents\n",
            "specific_needs: ['evacuation assistance']\n",
            "contact_info: John 555-0123\n",
            "time_mentioned: not specified\n",
            "additional_details: elderly residents unable to evacuate alone\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's break down the user's input. The disaster report mentions a house fire at 123 Oak Street. So, the location is clearly 123 Oak Street. The disaster type here is a fire. Now, the report says two elderly residents need help evacuating. That's important for urgency level and specific needs.\n",
            "\n",
            "The urgency level should be high because a house fire is an immediate danger. The people affected are two elderly residents. Specific needs would involve evac \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP. \n",
            "Answer:\n",
            "\n",
            "Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\n",
            "\n",
            "\n",
            "location: Kathmandu\n",
            "disaster_type: building collapse\n",
            "urgency_level: critical\n",
            "people_affected: 20 people trapped\n",
            "specific_needs: ['heavy rescue equipment', 'trained rescue personnel']\n",
            "contact_info: not provided\n",
            "time_mentioned: ASAP\n",
            "additional_details: voices heard from under debris\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let's tackle this query. The user provided a disaster report about a building collapse in Kathmandu with 20 people trapped. First, I need to extract the structured information as per the specified format.\n",
            "\n",
            "Starting with location: The report mentions Kathmandu, so that's straightforward. Disaster type is a building collapse, which is a structural disaster. Urgency level is \"ASAP\" as per the note, so I'll put that as high. People affected are  \n",
            "Extracted:\n",
            "\n",
            "-------------------- Question:\n",
            "Building collapsed in Kathmandu. 20 people trapped under debris. Can hear voices. Need heavy rescue equipment ASAP. \n",
            "Answer:\n",
            "\n",
            "Building collapse in Kathmandu with people trapped. Critical situation as people are heard under debris. Need specialized rescue equipment immediately.\n",
            "\n",
            "\n",
            "location: Kathmandu\n",
            "disaster_type: building collapse\n",
            "urgency_level: critical\n",
            "people_affected: 20 people trapped\n",
            "specific_needs: ['heavy rescue equipment', 'trained rescue personnel']\n",
            "contact_info: not provided\n",
            "time_mentioned: ASAP\n",
            "additional_details: voices heard from under debris\n",
            "\n",
            " \n",
            "Response:\n",
            "<think>\n",
            "Okay, let me try to figure out how to process this disaster report. The user provided a message about a building collapse in Kathmandu with 20 people trapped. They mentioned hearing voices and needing heavy rescue equipment ASAP. \n",
            "\n",
            "First, I need to extract the structured information as per the given format. Let me go through each part step by step.\n",
            "\n",
            "Location: The report says \"Building collapsed in Kathmandu,\" so the location is Kathmandu. That's straightforward.\n",
            "\n",
            "Dis \n",
            "Extracted:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=0.00011494832561425028, metrics={'train_runtime': 165.7797, 'train_samples_per_second': 0.121, 'train_steps_per_second': 0.06, 'total_flos': 0.0, 'train_loss': 0.00011494832561425028})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ],
      "metadata": {
        "id": "AFI1e1tfIkzw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_gguf(\"model\", tokenizer, quantization_method=\"q4_k_m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCyQeNW6Lev6",
        "outputId": "4da9f2d8-a815-43c7-d7c6-b9f93873346b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 3.6G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 2.87 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 23/36 [00:01<00:00, 19.18it/s]\n",
            "We will save to Disk and not RAM now.\n",
            "100%|██████████| 36/36 [00:49<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving model/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting qwen3 model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at model into f16 GGUF format.\n",
            "The output location will be /content/model/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: model\n",
            "INFO:hf-to-gguf:Model architecture: Qwen3ForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {2560, 151936}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.0.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.1.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.2.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.3.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.4.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.5.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.6.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.7.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.8.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.9.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.10.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.11.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.12.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.13.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.14.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.15.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.16.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.17.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.18.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.19.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.20.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.21.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.22.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.23.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.24.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.25.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.26.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.27.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.28.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.29.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.30.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.31.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.32.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.33.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.34.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.34.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.34.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.34.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.34.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.34.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.35.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.35.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.35.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.35.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.35.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.35.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 40960\n",
            "INFO:hf-to-gguf:gguf: embedding length = 2560\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 9728\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:gguf.vocab:Adding 151387 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type eos to 151645\n",
            "INFO:gguf.vocab:Setting special token type pad to 151654\n",
            "INFO:gguf.vocab:Setting add_bos_token to False\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/model/unsloth.F16.gguf: n_tensors = 398, total_size = 8.0G\n",
            "Writing: 100%|██████████| 8.05G/8.05G [06:08<00:00, 21.8Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/model/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/model/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 5588 (2589ad37)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/model/unsloth.F16.gguf' to '/content/model/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 398 tensors from /content/model/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = qwen3\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Model\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 4.0B\n",
            "llama_model_loader: - kv   4:                          qwen3.block_count u32              = 36\n",
            "llama_model_loader: - kv   5:                       qwen3.context_length u32              = 40960\n",
            "llama_model_loader: - kv   6:                     qwen3.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   7:                  qwen3.feed_forward_length u32              = 9728\n",
            "llama_model_loader: - kv   8:                 qwen3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              qwen3.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:                       qwen3.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  12:                 qwen3.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  13:               qwen3.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151645\n",
            "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151654\n",
            "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - type  f32:  145 tensors\n",
            "llama_model_loader: - type  f16:  253 tensors\n",
            "[   1/ 398]                   output_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   2/ 398]                    token_embd.weight - [ 2560, 151936,     1,     1], type =    f16, converting to q6_K .. size =   741.88 MiB ->   304.28 MiB\n",
            "[   3/ 398]                  blk.0.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[   4/ 398]             blk.0.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   5/ 398]               blk.0.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   6/ 398]             blk.0.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[   7/ 398]                  blk.0.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[   8/ 398]             blk.0.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   9/ 398]                  blk.0.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  10/ 398]                blk.0.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  11/ 398]                blk.0.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  12/ 398]                blk.0.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  13/ 398]                  blk.0.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  14/ 398]                  blk.1.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  15/ 398]             blk.1.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  16/ 398]               blk.1.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  17/ 398]             blk.1.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  18/ 398]                  blk.1.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  19/ 398]             blk.1.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  20/ 398]                  blk.1.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  21/ 398]                blk.1.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  22/ 398]                blk.1.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  23/ 398]                blk.1.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  24/ 398]                  blk.1.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  25/ 398]                  blk.2.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  26/ 398]             blk.2.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  27/ 398]               blk.2.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  28/ 398]             blk.2.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  29/ 398]                  blk.2.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  30/ 398]             blk.2.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  31/ 398]                  blk.2.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  32/ 398]                blk.2.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  33/ 398]                blk.2.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  34/ 398]                blk.2.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  35/ 398]                  blk.2.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  36/ 398]                  blk.3.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  37/ 398]             blk.3.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  38/ 398]               blk.3.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  39/ 398]             blk.3.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  40/ 398]                  blk.3.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  41/ 398]             blk.3.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  42/ 398]                  blk.3.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  43/ 398]                blk.3.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  44/ 398]                blk.3.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  45/ 398]                blk.3.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  46/ 398]                  blk.3.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  47/ 398]                  blk.4.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  48/ 398]             blk.4.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  49/ 398]               blk.4.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  50/ 398]             blk.4.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  51/ 398]                  blk.4.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  52/ 398]             blk.4.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  53/ 398]                  blk.4.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  54/ 398]                blk.4.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  55/ 398]                blk.4.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  56/ 398]                blk.4.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  57/ 398]                  blk.4.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  58/ 398]                  blk.5.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  59/ 398]             blk.5.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  60/ 398]               blk.5.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  61/ 398]             blk.5.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  62/ 398]                  blk.5.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  63/ 398]             blk.5.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  64/ 398]                  blk.5.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  65/ 398]                blk.5.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  66/ 398]                blk.5.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  67/ 398]                blk.5.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  68/ 398]                  blk.5.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  69/ 398]                  blk.6.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  70/ 398]             blk.6.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  71/ 398]               blk.6.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  72/ 398]             blk.6.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  73/ 398]                  blk.6.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  74/ 398]             blk.6.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  75/ 398]                  blk.6.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  76/ 398]                blk.6.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  77/ 398]                blk.6.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  78/ 398]                blk.6.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  79/ 398]                  blk.6.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  80/ 398]                  blk.7.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  81/ 398]             blk.7.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  82/ 398]               blk.7.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  83/ 398]             blk.7.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  84/ 398]                  blk.7.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  85/ 398]             blk.7.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  86/ 398]                  blk.7.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  87/ 398]                blk.7.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  88/ 398]                blk.7.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  89/ 398]                blk.7.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  90/ 398]                  blk.7.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  91/ 398]                  blk.8.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  92/ 398]             blk.8.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  93/ 398]               blk.8.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  94/ 398]             blk.8.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  95/ 398]                  blk.8.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  96/ 398]             blk.8.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  97/ 398]                  blk.8.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  98/ 398]                blk.8.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  99/ 398]                blk.8.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 100/ 398]                blk.8.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 101/ 398]                  blk.8.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 102/ 398]                  blk.9.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 103/ 398]             blk.9.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 104/ 398]               blk.9.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 105/ 398]             blk.9.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 106/ 398]                  blk.9.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 107/ 398]             blk.9.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 108/ 398]                  blk.9.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 109/ 398]                blk.9.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 110/ 398]                blk.9.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 111/ 398]                blk.9.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 112/ 398]                  blk.9.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 113/ 398]                 blk.10.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 114/ 398]            blk.10.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 115/ 398]              blk.10.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 116/ 398]            blk.10.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 117/ 398]                 blk.10.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 118/ 398]            blk.10.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 119/ 398]                 blk.10.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 120/ 398]               blk.10.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 121/ 398]               blk.10.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 122/ 398]               blk.10.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 123/ 398]                 blk.10.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 124/ 398]                 blk.11.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 125/ 398]            blk.11.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 126/ 398]              blk.11.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 127/ 398]            blk.11.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 128/ 398]                 blk.11.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 129/ 398]            blk.11.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 130/ 398]                 blk.11.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 131/ 398]               blk.11.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 132/ 398]               blk.11.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 133/ 398]               blk.11.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 134/ 398]                 blk.11.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 135/ 398]                 blk.12.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 136/ 398]            blk.12.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 137/ 398]              blk.12.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 138/ 398]            blk.12.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 139/ 398]                 blk.12.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 140/ 398]            blk.12.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 141/ 398]                 blk.12.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 142/ 398]               blk.12.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 143/ 398]               blk.12.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 144/ 398]               blk.12.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 145/ 398]                 blk.12.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 146/ 398]                 blk.13.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 147/ 398]            blk.13.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 148/ 398]              blk.13.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 149/ 398]            blk.13.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 150/ 398]                 blk.13.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 151/ 398]            blk.13.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 152/ 398]                 blk.13.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 153/ 398]               blk.13.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 154/ 398]               blk.13.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 155/ 398]               blk.13.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 156/ 398]                 blk.13.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 157/ 398]                 blk.14.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 158/ 398]            blk.14.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 159/ 398]              blk.14.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 160/ 398]            blk.14.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 161/ 398]                 blk.14.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 162/ 398]            blk.14.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 163/ 398]                 blk.14.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 164/ 398]               blk.14.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 165/ 398]               blk.14.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 166/ 398]               blk.14.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 167/ 398]                 blk.14.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 168/ 398]                 blk.15.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 169/ 398]            blk.15.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 170/ 398]              blk.15.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 171/ 398]            blk.15.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 172/ 398]                 blk.15.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 173/ 398]            blk.15.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 174/ 398]                 blk.15.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 175/ 398]               blk.15.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 176/ 398]               blk.15.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 177/ 398]               blk.15.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 178/ 398]                 blk.15.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 179/ 398]                 blk.16.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 180/ 398]            blk.16.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 181/ 398]              blk.16.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 182/ 398]            blk.16.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 183/ 398]                 blk.16.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 184/ 398]            blk.16.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 185/ 398]                 blk.16.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 186/ 398]               blk.16.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 187/ 398]               blk.16.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 188/ 398]               blk.16.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 189/ 398]                 blk.16.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 190/ 398]                 blk.17.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 191/ 398]            blk.17.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 192/ 398]              blk.17.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 193/ 398]            blk.17.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 194/ 398]                 blk.17.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 195/ 398]            blk.17.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 196/ 398]                 blk.17.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 197/ 398]               blk.17.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 198/ 398]               blk.17.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 199/ 398]               blk.17.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 200/ 398]                 blk.17.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 201/ 398]                 blk.18.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 202/ 398]            blk.18.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 203/ 398]              blk.18.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 204/ 398]            blk.18.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 205/ 398]                 blk.18.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 206/ 398]            blk.18.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 207/ 398]                 blk.18.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 208/ 398]               blk.18.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 209/ 398]               blk.18.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 210/ 398]               blk.18.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 211/ 398]                 blk.18.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 212/ 398]                 blk.19.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 213/ 398]            blk.19.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 214/ 398]              blk.19.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 215/ 398]            blk.19.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 216/ 398]                 blk.19.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 217/ 398]            blk.19.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 218/ 398]                 blk.19.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 219/ 398]               blk.19.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 220/ 398]               blk.19.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 221/ 398]               blk.19.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 222/ 398]                 blk.19.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 223/ 398]                 blk.20.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 224/ 398]            blk.20.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 225/ 398]              blk.20.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 226/ 398]            blk.20.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 227/ 398]                 blk.20.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 228/ 398]            blk.20.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 229/ 398]                 blk.20.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 230/ 398]               blk.20.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 231/ 398]               blk.20.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 232/ 398]               blk.20.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 233/ 398]                 blk.20.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 234/ 398]                 blk.21.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 235/ 398]            blk.21.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 236/ 398]              blk.21.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 237/ 398]            blk.21.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 238/ 398]                 blk.21.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 239/ 398]            blk.21.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 240/ 398]                 blk.21.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 241/ 398]               blk.21.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 242/ 398]               blk.21.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 243/ 398]               blk.21.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 244/ 398]                 blk.21.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 245/ 398]                 blk.22.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 246/ 398]            blk.22.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 247/ 398]              blk.22.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 248/ 398]            blk.22.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 249/ 398]                 blk.22.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 250/ 398]            blk.22.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 251/ 398]                 blk.22.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 252/ 398]               blk.22.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 253/ 398]               blk.22.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 254/ 398]               blk.22.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 255/ 398]                 blk.22.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 256/ 398]                 blk.23.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 257/ 398]            blk.23.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 258/ 398]              blk.23.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 259/ 398]            blk.23.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 260/ 398]                 blk.23.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 261/ 398]            blk.23.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 262/ 398]                 blk.23.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 263/ 398]               blk.23.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 264/ 398]               blk.23.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 265/ 398]               blk.23.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 266/ 398]                 blk.23.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 267/ 398]                 blk.24.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 268/ 398]            blk.24.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 269/ 398]              blk.24.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 270/ 398]            blk.24.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 271/ 398]                 blk.24.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 272/ 398]            blk.24.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 273/ 398]                 blk.24.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 274/ 398]               blk.24.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 275/ 398]               blk.24.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 276/ 398]               blk.24.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 277/ 398]                 blk.24.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 278/ 398]                 blk.25.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 279/ 398]            blk.25.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 280/ 398]              blk.25.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 281/ 398]            blk.25.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 282/ 398]                 blk.25.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 283/ 398]            blk.25.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 284/ 398]                 blk.25.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 285/ 398]               blk.25.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 286/ 398]               blk.25.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 287/ 398]               blk.25.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 288/ 398]                 blk.25.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 289/ 398]                 blk.26.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 290/ 398]            blk.26.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 291/ 398]              blk.26.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 292/ 398]            blk.26.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 293/ 398]                 blk.26.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 294/ 398]            blk.26.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 295/ 398]                 blk.26.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 296/ 398]               blk.26.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 297/ 398]               blk.26.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 298/ 398]               blk.26.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 299/ 398]                 blk.26.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 300/ 398]                 blk.27.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 301/ 398]            blk.27.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 302/ 398]              blk.27.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 303/ 398]            blk.27.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 304/ 398]                 blk.27.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 305/ 398]            blk.27.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 306/ 398]                 blk.27.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 307/ 398]               blk.27.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 308/ 398]               blk.27.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 309/ 398]               blk.27.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 310/ 398]                 blk.27.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 311/ 398]                 blk.28.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 312/ 398]            blk.28.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 313/ 398]              blk.28.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 314/ 398]            blk.28.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 315/ 398]                 blk.28.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 316/ 398]            blk.28.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 317/ 398]                 blk.28.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 318/ 398]               blk.28.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 319/ 398]               blk.28.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 320/ 398]               blk.28.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 321/ 398]                 blk.28.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 322/ 398]                 blk.29.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 323/ 398]            blk.29.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 324/ 398]              blk.29.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 325/ 398]            blk.29.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 326/ 398]                 blk.29.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 327/ 398]            blk.29.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 328/ 398]                 blk.29.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 329/ 398]               blk.29.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 330/ 398]               blk.29.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 331/ 398]               blk.29.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 332/ 398]                 blk.29.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 333/ 398]                 blk.30.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 334/ 398]            blk.30.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 335/ 398]              blk.30.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 336/ 398]            blk.30.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 337/ 398]                 blk.30.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 338/ 398]            blk.30.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 339/ 398]                 blk.30.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 340/ 398]               blk.30.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 341/ 398]               blk.30.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 342/ 398]               blk.30.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 343/ 398]                 blk.30.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 344/ 398]                 blk.31.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 345/ 398]            blk.31.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 346/ 398]              blk.31.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 347/ 398]            blk.31.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 348/ 398]                 blk.31.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 349/ 398]            blk.31.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 350/ 398]                 blk.31.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 351/ 398]               blk.31.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 352/ 398]               blk.31.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 353/ 398]               blk.31.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 354/ 398]                 blk.31.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 355/ 398]                 blk.32.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 356/ 398]            blk.32.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 357/ 398]              blk.32.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 358/ 398]            blk.32.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 359/ 398]                 blk.32.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 360/ 398]            blk.32.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 361/ 398]                 blk.32.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 362/ 398]               blk.32.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 363/ 398]               blk.32.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 364/ 398]               blk.32.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 365/ 398]                 blk.32.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 366/ 398]                 blk.33.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 367/ 398]            blk.33.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 368/ 398]              blk.33.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 369/ 398]            blk.33.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 370/ 398]                 blk.33.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 371/ 398]            blk.33.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 372/ 398]                 blk.33.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 373/ 398]               blk.33.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 374/ 398]               blk.33.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 375/ 398]               blk.33.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 376/ 398]                 blk.33.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 377/ 398]                 blk.34.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 378/ 398]            blk.34.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 379/ 398]              blk.34.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 380/ 398]            blk.34.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 381/ 398]                 blk.34.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 382/ 398]            blk.34.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 383/ 398]                 blk.34.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 384/ 398]               blk.34.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 385/ 398]               blk.34.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 386/ 398]               blk.34.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 387/ 398]                 blk.34.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 388/ 398]                 blk.35.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 389/ 398]            blk.35.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 390/ 398]              blk.35.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 391/ 398]            blk.35.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 392/ 398]                 blk.35.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 393/ 398]            blk.35.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 394/ 398]                 blk.35.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 395/ 398]               blk.35.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 396/ 398]               blk.35.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 397/ 398]               blk.35.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 398/ 398]                 blk.35.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "llama_model_quantize_impl: model size  =  7672.62 MB\n",
            "llama_model_quantize_impl: quant size  =  2375.91 MB\n",
            "\n",
            "main: quantize time = 514534.10 ms\n",
            "main:    total time = 514534.10 ms\n",
            "Unsloth: Conversion completed! Output location: /content/model/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub_gguf(\n",
        "    \"NisalDeZoysa/disaster-response-grpo-qwen3-4B\",  # ✅ Correct format\n",
        "    tokenizer,\n",
        "    quantization_method=\"q4_k_m\",\n",
        "    token=\"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\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a9340b14bd8c42149affacdbb583c33a",
            "68b8b097896241cd87573255c9c57f77",
            "b092c1a7922045bbbbc9453b91cf0d6d",
            "1be2d5af29e34c94a5a8bdf9c6da69cb",
            "70fbfd5d0352474bb4a0ba039266b439",
            "7c9e9bb549b24ad9b12a2ef4549d388a",
            "f052fbd3adb2495c9f904e9e9db11a8a",
            "8241c2e2422842b9875982e11377a086",
            "b738f9f1a6e64fbb9825e9b5b1a0143c",
            "089d7d2a184c490581cbe2a5141b69ad",
            "8f00c63122304fd699b51fd6e63ed249",
            "6389d4ab46d943d7bcd116e735fd0f88",
            "ce030858ac7445ce9d8aad9857cac28f",
            "cfb7f01961f64087823b9e70973dbf1f",
            "d51ca97c7bc54bdeb402f9992b96d628",
            "26d4d2439ab8475abc4ecc7ece94e541",
            "68d04c146cba4f6f99d0d7ce4ad29af8",
            "b9e43b8c67b9406683191ecf1f99907d",
            "9b68a60ca05c47ffa70d4235caab720b",
            "e8d988bf379349419b66408ffc14df9e",
            "c6cd22cac26a4a1a880624536f1bdc9f",
            "32e180a9b48644808f862836ad7c2c7f"
          ]
        },
        "id": "7OP2HP13Lg-p",
        "outputId": "1ac4f912-32ce-46a9-8289-7c6d0ed62213"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 2.87 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [01:14<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving NisalDeZoysa/disaster-response-grpo-qwen3-4B/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving NisalDeZoysa/disaster-response-grpo-qwen3-4B/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at NisalDeZoysa/disaster-response-grpo-qwen3-4B into f16 GGUF format.\n",
            "The output location will be /content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: disaster-response-grpo-qwen3-4B\n",
            "INFO:hf-to-gguf:Model architecture: Qwen3ForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {2560, 151936}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.0.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.1.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.2.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.3.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.4.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.5.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.6.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.7.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.8.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_q_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.9.attn_k_norm.weight,  torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.10.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.11.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.12.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.13.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.14.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.15.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.16.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.17.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.18.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.19.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.20.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.21.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.22.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.23.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.24.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.25.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.26.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.27.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.28.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.29.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.30.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.31.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.32.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.33.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.34.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.34.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.34.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.34.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.34.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.34.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.35.attn_q.weight,      torch.float16 --> F16, shape = {2560, 4096}\n",
            "INFO:hf-to-gguf:blk.35.attn_k.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.35.attn_v.weight,      torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight, torch.float16 --> F16, shape = {4096, 2560}\n",
            "INFO:hf-to-gguf:blk.35.ffn_gate.weight,    torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,      torch.float16 --> F16, shape = {2560, 9728}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,    torch.float16 --> F16, shape = {9728, 2560}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,   torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,    torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.35.attn_q_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:blk.35.attn_k_norm.weight, torch.float16 --> F32, shape = {128}\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 40960\n",
            "INFO:hf-to-gguf:gguf: embedding length = 2560\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 9728\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:gguf.vocab:Adding 151387 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type eos to 151645\n",
            "INFO:gguf.vocab:Setting special token type pad to 151654\n",
            "INFO:gguf.vocab:Setting add_bos_token to False\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf: n_tensors = 398, total_size = 8.0G\n",
            "Writing: 100%|██████████| 8.05G/8.05G [05:44<00:00, 23.4Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 5588 (2589ad37)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf' to '/content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 25 key-value pairs and 398 tensors from /content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = qwen3\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Disaster Response Grpo Qwen3 4B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = disaster-response-grpo-qwen3\n",
            "llama_model_loader: - kv   4:                         general.size_label str              = 4B\n",
            "llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36\n",
            "llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960\n",
            "llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728\n",
            "llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  16:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = qwen2\n",
            "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 151645\n",
            "llama_model_loader: - kv  23:            tokenizer.ggml.padding_token_id u32              = 151654\n",
            "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - type  f32:  145 tensors\n",
            "llama_model_loader: - type  f16:  253 tensors\n",
            "[   1/ 398]                   output_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   2/ 398]                    token_embd.weight - [ 2560, 151936,     1,     1], type =    f16, converting to q6_K .. size =   741.88 MiB ->   304.28 MiB\n",
            "[   3/ 398]                  blk.0.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[   4/ 398]             blk.0.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   5/ 398]               blk.0.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   6/ 398]             blk.0.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[   7/ 398]                  blk.0.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[   8/ 398]             blk.0.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   9/ 398]                  blk.0.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  10/ 398]                blk.0.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  11/ 398]                blk.0.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  12/ 398]                blk.0.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  13/ 398]                  blk.0.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  14/ 398]                  blk.1.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  15/ 398]             blk.1.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  16/ 398]               blk.1.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  17/ 398]             blk.1.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  18/ 398]                  blk.1.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  19/ 398]             blk.1.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  20/ 398]                  blk.1.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  21/ 398]                blk.1.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  22/ 398]                blk.1.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  23/ 398]                blk.1.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  24/ 398]                  blk.1.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  25/ 398]                  blk.2.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  26/ 398]             blk.2.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  27/ 398]               blk.2.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  28/ 398]             blk.2.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  29/ 398]                  blk.2.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  30/ 398]             blk.2.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  31/ 398]                  blk.2.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  32/ 398]                blk.2.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  33/ 398]                blk.2.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  34/ 398]                blk.2.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  35/ 398]                  blk.2.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  36/ 398]                  blk.3.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  37/ 398]             blk.3.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  38/ 398]               blk.3.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  39/ 398]             blk.3.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  40/ 398]                  blk.3.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  41/ 398]             blk.3.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  42/ 398]                  blk.3.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  43/ 398]                blk.3.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  44/ 398]                blk.3.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  45/ 398]                blk.3.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  46/ 398]                  blk.3.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  47/ 398]                  blk.4.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  48/ 398]             blk.4.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  49/ 398]               blk.4.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  50/ 398]             blk.4.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  51/ 398]                  blk.4.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  52/ 398]             blk.4.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  53/ 398]                  blk.4.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  54/ 398]                blk.4.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  55/ 398]                blk.4.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  56/ 398]                blk.4.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  57/ 398]                  blk.4.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  58/ 398]                  blk.5.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  59/ 398]             blk.5.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  60/ 398]               blk.5.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  61/ 398]             blk.5.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  62/ 398]                  blk.5.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  63/ 398]             blk.5.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  64/ 398]                  blk.5.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  65/ 398]                blk.5.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  66/ 398]                blk.5.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  67/ 398]                blk.5.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  68/ 398]                  blk.5.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  69/ 398]                  blk.6.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  70/ 398]             blk.6.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  71/ 398]               blk.6.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  72/ 398]             blk.6.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  73/ 398]                  blk.6.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  74/ 398]             blk.6.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  75/ 398]                  blk.6.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  76/ 398]                blk.6.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[  77/ 398]                blk.6.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  78/ 398]                blk.6.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  79/ 398]                  blk.6.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  80/ 398]                  blk.7.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  81/ 398]             blk.7.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  82/ 398]               blk.7.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  83/ 398]             blk.7.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  84/ 398]                  blk.7.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  85/ 398]             blk.7.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  86/ 398]                  blk.7.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  87/ 398]                blk.7.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  88/ 398]                blk.7.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  89/ 398]                blk.7.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  90/ 398]                  blk.7.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  91/ 398]                  blk.8.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  92/ 398]             blk.8.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  93/ 398]               blk.8.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  94/ 398]             blk.8.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  95/ 398]                  blk.8.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[  96/ 398]             blk.8.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[  97/ 398]                  blk.8.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  98/ 398]                blk.8.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[  99/ 398]                blk.8.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 100/ 398]                blk.8.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 101/ 398]                  blk.8.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 102/ 398]                  blk.9.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 103/ 398]             blk.9.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 104/ 398]               blk.9.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 105/ 398]             blk.9.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 106/ 398]                  blk.9.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 107/ 398]             blk.9.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 108/ 398]                  blk.9.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 109/ 398]                blk.9.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 110/ 398]                blk.9.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 111/ 398]                blk.9.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 112/ 398]                  blk.9.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 113/ 398]                 blk.10.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 114/ 398]            blk.10.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 115/ 398]              blk.10.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 116/ 398]            blk.10.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 117/ 398]                 blk.10.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 118/ 398]            blk.10.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 119/ 398]                 blk.10.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 120/ 398]               blk.10.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 121/ 398]               blk.10.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 122/ 398]               blk.10.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 123/ 398]                 blk.10.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 124/ 398]                 blk.11.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 125/ 398]            blk.11.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 126/ 398]              blk.11.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 127/ 398]            blk.11.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 128/ 398]                 blk.11.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 129/ 398]            blk.11.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 130/ 398]                 blk.11.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 131/ 398]               blk.11.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 132/ 398]               blk.11.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 133/ 398]               blk.11.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 134/ 398]                 blk.11.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 135/ 398]                 blk.12.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 136/ 398]            blk.12.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 137/ 398]              blk.12.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 138/ 398]            blk.12.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 139/ 398]                 blk.12.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 140/ 398]            blk.12.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 141/ 398]                 blk.12.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 142/ 398]               blk.12.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 143/ 398]               blk.12.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 144/ 398]               blk.12.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 145/ 398]                 blk.12.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 146/ 398]                 blk.13.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 147/ 398]            blk.13.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 148/ 398]              blk.13.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 149/ 398]            blk.13.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 150/ 398]                 blk.13.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 151/ 398]            blk.13.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 152/ 398]                 blk.13.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 153/ 398]               blk.13.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 154/ 398]               blk.13.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 155/ 398]               blk.13.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 156/ 398]                 blk.13.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 157/ 398]                 blk.14.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 158/ 398]            blk.14.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 159/ 398]              blk.14.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 160/ 398]            blk.14.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 161/ 398]                 blk.14.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 162/ 398]            blk.14.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 163/ 398]                 blk.14.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 164/ 398]               blk.14.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 165/ 398]               blk.14.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 166/ 398]               blk.14.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 167/ 398]                 blk.14.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 168/ 398]                 blk.15.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 169/ 398]            blk.15.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 170/ 398]              blk.15.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 171/ 398]            blk.15.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 172/ 398]                 blk.15.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 173/ 398]            blk.15.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 174/ 398]                 blk.15.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 175/ 398]               blk.15.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 176/ 398]               blk.15.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 177/ 398]               blk.15.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 178/ 398]                 blk.15.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 179/ 398]                 blk.16.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 180/ 398]            blk.16.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 181/ 398]              blk.16.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 182/ 398]            blk.16.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 183/ 398]                 blk.16.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 184/ 398]            blk.16.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 185/ 398]                 blk.16.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 186/ 398]               blk.16.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 187/ 398]               blk.16.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 188/ 398]               blk.16.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 189/ 398]                 blk.16.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 190/ 398]                 blk.17.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 191/ 398]            blk.17.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 192/ 398]              blk.17.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 193/ 398]            blk.17.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 194/ 398]                 blk.17.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 195/ 398]            blk.17.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 196/ 398]                 blk.17.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 197/ 398]               blk.17.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 198/ 398]               blk.17.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 199/ 398]               blk.17.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 200/ 398]                 blk.17.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 201/ 398]                 blk.18.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 202/ 398]            blk.18.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 203/ 398]              blk.18.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 204/ 398]            blk.18.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 205/ 398]                 blk.18.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 206/ 398]            blk.18.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 207/ 398]                 blk.18.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 208/ 398]               blk.18.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 209/ 398]               blk.18.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 210/ 398]               blk.18.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 211/ 398]                 blk.18.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 212/ 398]                 blk.19.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 213/ 398]            blk.19.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 214/ 398]              blk.19.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 215/ 398]            blk.19.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 216/ 398]                 blk.19.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 217/ 398]            blk.19.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 218/ 398]                 blk.19.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 219/ 398]               blk.19.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 220/ 398]               blk.19.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 221/ 398]               blk.19.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 222/ 398]                 blk.19.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 223/ 398]                 blk.20.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 224/ 398]            blk.20.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 225/ 398]              blk.20.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 226/ 398]            blk.20.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 227/ 398]                 blk.20.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 228/ 398]            blk.20.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 229/ 398]                 blk.20.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 230/ 398]               blk.20.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 231/ 398]               blk.20.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 232/ 398]               blk.20.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 233/ 398]                 blk.20.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 234/ 398]                 blk.21.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 235/ 398]            blk.21.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 236/ 398]              blk.21.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 237/ 398]            blk.21.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 238/ 398]                 blk.21.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 239/ 398]            blk.21.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 240/ 398]                 blk.21.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 241/ 398]               blk.21.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 242/ 398]               blk.21.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 243/ 398]               blk.21.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 244/ 398]                 blk.21.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 245/ 398]                 blk.22.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 246/ 398]            blk.22.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 247/ 398]              blk.22.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 248/ 398]            blk.22.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 249/ 398]                 blk.22.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 250/ 398]            blk.22.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 251/ 398]                 blk.22.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 252/ 398]               blk.22.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 253/ 398]               blk.22.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 254/ 398]               blk.22.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 255/ 398]                 blk.22.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 256/ 398]                 blk.23.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 257/ 398]            blk.23.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 258/ 398]              blk.23.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 259/ 398]            blk.23.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 260/ 398]                 blk.23.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 261/ 398]            blk.23.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 262/ 398]                 blk.23.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 263/ 398]               blk.23.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 264/ 398]               blk.23.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 265/ 398]               blk.23.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 266/ 398]                 blk.23.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 267/ 398]                 blk.24.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 268/ 398]            blk.24.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 269/ 398]              blk.24.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 270/ 398]            blk.24.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 271/ 398]                 blk.24.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 272/ 398]            blk.24.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 273/ 398]                 blk.24.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 274/ 398]               blk.24.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 275/ 398]               blk.24.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 276/ 398]               blk.24.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 277/ 398]                 blk.24.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 278/ 398]                 blk.25.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 279/ 398]            blk.25.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 280/ 398]              blk.25.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 281/ 398]            blk.25.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 282/ 398]                 blk.25.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 283/ 398]            blk.25.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 284/ 398]                 blk.25.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 285/ 398]               blk.25.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 286/ 398]               blk.25.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 287/ 398]               blk.25.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 288/ 398]                 blk.25.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 289/ 398]                 blk.26.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 290/ 398]            blk.26.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 291/ 398]              blk.26.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 292/ 398]            blk.26.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 293/ 398]                 blk.26.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 294/ 398]            blk.26.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 295/ 398]                 blk.26.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 296/ 398]               blk.26.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 297/ 398]               blk.26.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 298/ 398]               blk.26.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 299/ 398]                 blk.26.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 300/ 398]                 blk.27.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 301/ 398]            blk.27.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 302/ 398]              blk.27.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 303/ 398]            blk.27.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 304/ 398]                 blk.27.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 305/ 398]            blk.27.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 306/ 398]                 blk.27.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 307/ 398]               blk.27.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 308/ 398]               blk.27.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 309/ 398]               blk.27.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 310/ 398]                 blk.27.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 311/ 398]                 blk.28.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 312/ 398]            blk.28.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 313/ 398]              blk.28.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 314/ 398]            blk.28.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 315/ 398]                 blk.28.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 316/ 398]            blk.28.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 317/ 398]                 blk.28.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 318/ 398]               blk.28.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 319/ 398]               blk.28.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 320/ 398]               blk.28.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 321/ 398]                 blk.28.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 322/ 398]                 blk.29.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 323/ 398]            blk.29.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 324/ 398]              blk.29.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 325/ 398]            blk.29.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 326/ 398]                 blk.29.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 327/ 398]            blk.29.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 328/ 398]                 blk.29.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 329/ 398]               blk.29.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 330/ 398]               blk.29.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 331/ 398]               blk.29.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 332/ 398]                 blk.29.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 333/ 398]                 blk.30.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 334/ 398]            blk.30.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 335/ 398]              blk.30.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 336/ 398]            blk.30.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 337/ 398]                 blk.30.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 338/ 398]            blk.30.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 339/ 398]                 blk.30.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 340/ 398]               blk.30.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 341/ 398]               blk.30.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 342/ 398]               blk.30.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 343/ 398]                 blk.30.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 344/ 398]                 blk.31.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 345/ 398]            blk.31.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 346/ 398]              blk.31.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 347/ 398]            blk.31.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 348/ 398]                 blk.31.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 349/ 398]            blk.31.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 350/ 398]                 blk.31.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 351/ 398]               blk.31.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 352/ 398]               blk.31.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 353/ 398]               blk.31.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 354/ 398]                 blk.31.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 355/ 398]                 blk.32.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 356/ 398]            blk.32.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 357/ 398]              blk.32.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 358/ 398]            blk.32.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 359/ 398]                 blk.32.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 360/ 398]            blk.32.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 361/ 398]                 blk.32.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 362/ 398]               blk.32.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 363/ 398]               blk.32.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 364/ 398]               blk.32.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 365/ 398]                 blk.32.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 366/ 398]                 blk.33.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 367/ 398]            blk.33.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 368/ 398]              blk.33.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 369/ 398]            blk.33.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 370/ 398]                 blk.33.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 371/ 398]            blk.33.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 372/ 398]                 blk.33.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 373/ 398]               blk.33.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 374/ 398]               blk.33.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 375/ 398]               blk.33.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 376/ 398]                 blk.33.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 377/ 398]                 blk.34.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 378/ 398]            blk.34.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 379/ 398]              blk.34.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 380/ 398]            blk.34.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 381/ 398]                 blk.34.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 382/ 398]            blk.34.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 383/ 398]                 blk.34.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 384/ 398]               blk.34.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 385/ 398]               blk.34.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 386/ 398]               blk.34.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 387/ 398]                 blk.34.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 388/ 398]                 blk.35.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 389/ 398]            blk.35.attn_k_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 390/ 398]              blk.35.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 391/ 398]            blk.35.attn_output.weight - [ 4096,  2560,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 392/ 398]                 blk.35.attn_q.weight - [ 2560,  4096,     1,     1], type =    f16, converting to q4_K .. size =    20.00 MiB ->     5.62 MiB\n",
            "[ 393/ 398]            blk.35.attn_q_norm.weight - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[ 394/ 398]                 blk.35.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 395/ 398]               blk.35.ffn_down.weight - [ 9728,  2560,     1,     1], type =    f16, converting to q6_K .. size =    47.50 MiB ->    19.48 MiB\n",
            "[ 396/ 398]               blk.35.ffn_gate.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "[ 397/ 398]               blk.35.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 398/ 398]                 blk.35.ffn_up.weight - [ 2560,  9728,     1,     1], type =    f16, converting to q4_K .. size =    47.50 MiB ->    13.36 MiB\n",
            "llama_model_quantize_impl: model size  =  7672.62 MB\n",
            "llama_model_quantize_impl: quant size  =  2375.91 MB\n",
            "\n",
            "main: quantize time = 499746.89 ms\n",
            "main:    total time = 499746.89 ms\n",
            "Unsloth: Conversion completed! Output location: /content/NisalDeZoysa/disaster-response-grpo-qwen3-4B/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9340b14bd8c42149affacdbb583c33a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/2.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6389d4ab46d943d7bcd116e735fd0f88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/NisalDeZoysa/disaster-response-grpo-qwen3-4B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6rajS7pQ8pO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}